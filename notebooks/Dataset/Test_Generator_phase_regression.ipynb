{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search for root_dir and set working directory\n",
      "Working directory set to: /mnt/ssd/git/dynamic-cmr-models\n",
      "['/gpu:0', '/gpu:1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:04,333 INFO -------------------- Start --------------------\n",
      "2021-02-12 15:06:04,334 INFO Working directory: /mnt/ssd/git/dynamic-cmr-models.\n",
      "2021-02-12 15:06:04,334 INFO Log file: ./logs/temp/PhaseRegression_tests.log\n",
      "2021-02-12 15:06:04,334 INFO Log level for console: INFO\n",
      "2021-02-12 15:06:04,335 INFO Is built with tensorflow: True\n",
      "2021-02-12 15:06:04,411 INFO Visible devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'), PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "2021-02-12 15:06:05,063 INFO Local devices: \n",
      " [name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18332941130773454465\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4192243884662179992\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7576701847785571546\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8749372306592218159\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 22926238720\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12710620917769042996\n",
      "physical_device_desc: \"device: 0, name: TITAN RTX, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 23561743872\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4855081647057650873\n",
      "physical_device_desc: \"device: 1, name: TITAN RTX, pci bus id: 0000:02:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GPU_IDS': '0,1', 'GPUS': ['/gpu:0', '/gpu:1'], 'SEED': 42, 'EXPERIMENT': 'temp/PhaseRegression_tests', 'MODEL_PATH': 'models/temp/PhaseRegression_tests/2021-02-12_15_06', 'TENSORBOARD_LOG_DIR': 'reports/tensorboard_logs/temp/PhaseRegression_tests/2021-02-12_15_06', 'CONFIG_PATH': 'reports/configs/temp/PhaseRegression_tests/2021-02-12_15_06', 'HISTORY_PATH': 'reports/history/temp/PhaseRegression_tests/2021-02-12_15_06', 'BATCHSIZE': 6, 'GENERATOR_WORKER': 6, 'DIM': [10, 64, 64], 'T_SHAPE': 35, 'SPACING': [10, 4, 4], 'DEPTH': 2, 'FILTERS': 32, 'M_POOL': [2, 2, 2], 'F_SIZE': [3, 3, 3], 'BORDER_MODE': 4, 'IMG_INTERPOLATION': 1, 'MSK_INTERPOLATION': 0, 'AUGMENT': True, 'AUGMENT_PROB': 0.8, 'SHUFFLE': True, 'RESAMPLE': True, 'SCALER': 'MinMax', 'DF_META': '/mnt/ssd/data/gcn/02_imported_4D_unfiltered/SAx_3D_dicomTags_phase', 'PHASES': 6, 'TARGET_SMOOTHING': True, 'SMOOTHING_KERNEL_SIZE': 10, 'SMOOTHING_LOWER_BORDER': 0.2, 'SMOOTHING_UPPER_BORDER': 0.4}\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------define logging and working directory\n",
    "from ProjectRoot import change_wd_to_project_root\n",
    "change_wd_to_project_root()\n",
    "from src.utils.Tensorflow_helper import choose_gpu_by_id\n",
    "# ------------------------------------------define GPU id/s to use\n",
    "GPU_IDS = '0,1'\n",
    "GPUS = choose_gpu_by_id(GPU_IDS)\n",
    "print(GPUS)\n",
    "# ------------------------------------------jupyter magic config\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# ------------------------------------------ import helpers\n",
    "# this should import glob, os, and many other standard libs\n",
    "from src.utils.Notebook_imports import *\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "# local imports\n",
    "from src.utils.Utils_io import Console_and_file_logger, init_config\n",
    "from src.visualization.Visualize import show_2D_or_3D\n",
    "from src.utils.KerasCallbacks import get_callbacks\n",
    "\n",
    "# import external libs\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "EXPERIMENT = 'temp/PhaseRegression_tests'\n",
    "timestemp = str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M\")) # ad a timestep to each project to make repeated experiments unique\n",
    "\n",
    "MODEL_PATH = os.path.join('models', EXPERIMENT, timestemp)\n",
    "TENSORBOARD_LOG_DIR = os.path.join('reports/tensorboard_logs', EXPERIMENT,timestemp)\n",
    "CONFIG_PATH = os.path.join('reports/configs/',EXPERIMENT,timestemp)\n",
    "HISTORY_PATH = os.path.join('reports/history/',EXPERIMENT,timestemp)\n",
    "\n",
    "# ------------------------------------------generator hyperparameters\n",
    "SEED = 42 # define a seed for the generator shuffle\n",
    "BATCHSIZE = 6 # 32, 64, 24, 16, 1 for 3D use: 4\n",
    "GENERATOR_WORKER = BATCHSIZE # if not set, use batchsize\n",
    "\n",
    "DIM = [10, 64, 64] # network input params for spacing of 3, (z,y,x)\n",
    "T_SHAPE = 35\n",
    "SPACING = [10, 4, 4] # if resample, resample to this spacing, (z,y,x)\n",
    "\n",
    "DEPTH = 2 # depth of the encoder\n",
    "FILTERS = 32 # initial number of filters, will be doubled after each downsampling block\n",
    "M_POOL = [2, 2, 2]# size of max-pooling used for downsampling and upsampling\n",
    "F_SIZE = [3, 3, 3] # conv filter size\n",
    "BORDER_MODE = cv2.BORDER_REFLECT_101 # border mode for the data generation\n",
    "IMG_INTERPOLATION = cv2.INTER_LINEAR # image interpolation in the genarator\n",
    "MSK_INTERPOLATION = cv2.INTER_NEAREST # mask interpolation in the generator\n",
    "AUGMENT = True # a compose of 2D augmentation (grid distortion, 90degree rotation, brightness and shift)\n",
    "AUGMENT_PROB = 0.8\n",
    "SHUFFLE = True\n",
    "RESAMPLE = True\n",
    "SCALER = 'MinMax' # MinMax Standard or Robust\n",
    "\n",
    "\n",
    "DF_META = '/mnt/ssd/data/gcn/02_imported_4D_unfiltered/SAx_3D_dicomTags_phase'\n",
    "# We define 5 target phases and a background phase for the pad/empty volumes \n",
    "PHASES = len(['ED#', 'MS#', 'ES#', 'PF#', 'MD#','pad backround manually added'])\n",
    "TARGET_SMOOTHING = True\n",
    "SMOOTHING_KERNEL_SIZE = 10\n",
    "SMOOTHING_LOWER_BORDER = 0.2\n",
    "SMOOTHING_UPPER_BORDER = 0.4\n",
    "\n",
    "\n",
    "Console_and_file_logger(EXPERIMENT, logging.INFO)\n",
    "config = init_config(config=locals(), save=True)\n",
    "print(config)\n",
    "logging.info('Is built with tensorflow: {}'.format(tf.test.is_built_with_cuda()))\n",
    "logging.info('Visible devices:\\n{}'.format(tf.config.list_physical_devices()))\n",
    "logging.info('Local devices: \\n {}'.format(device_lib.list_local_devices()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278\n"
     ]
    }
   ],
   "source": [
    "# zip the phase files in the following structure:\n",
    "#[[patient1_phase1, patient1_phase2, patient1_phase3, patient1_phase4, patient1_phase5],[patient2_phase1...] ...]\n",
    "\n",
    "images = sorted(glob.glob('/mnt/ssd/data/gcn/02_imported_4D_unfiltered/SAX/*clean.nrrd'))\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heck if we find each patient in the corresponding dataframe\n",
    "import re\n",
    "METADATA_FILE = config.get('DF_META', '/mnt/ssd/data/gcn/02_imported_4D_unfiltered/SAx_3D_dicomTags_phase')\n",
    "df = pd.read_csv(METADATA_FILE)\n",
    "DF_METADATA = df[['patient', 'ED#', 'MS#', 'ES#', 'PF#', 'MD#']]\n",
    "\n",
    "\n",
    "for x in images:\n",
    "    try:\n",
    "        patient_str = re.search('-(.{8})_', x).group(1).upper()\n",
    "        \n",
    "        assert(len(patient_str) == 8), 'matched patient ID from the phase sheet has a length of: {}'.format(len(patient_str))\n",
    "        # returns the indices in the following order: 'ED#', 'MS#', 'ES#', 'PF#', 'MD#'\n",
    "        # reduce by one, as the indexes start at 0, the excel-sheet at 1\n",
    "        ind = DF_METADATA[DF_METADATA.patient.str.contains(patient_str)][['ED#', 'MS#', 'ES#', 'PF#', 'MD#']]\n",
    "        indices = ind.values[0].astype(int) -1\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.info(patient_str)\n",
    "        logging.info(ind)\n",
    "        logging.info('indices: \\n{}'.format(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 10, 192, 138)\n",
      "3\n",
      "(42, 10, 192, 138)\n",
      "(5, 14)\n",
      "(5, 42)\n"
     ]
    }
   ],
   "source": [
    "# The length of our onehot vector must be the length of our 4D volume\n",
    "import SimpleITK as sitk\n",
    "from src.data.Dataset import split_one_4d_sitk_in_list_of_3d_sitk\n",
    "\n",
    "x = images[0]\n",
    "model_inputs = split_one_4d_sitk_in_list_of_3d_sitk(sitk.ReadImage(x))\n",
    "nda = [sitk.GetArrayFromImage(i) for i in model_inputs]\n",
    "nda = np.stack(nda)\n",
    "print(nda.shape)\n",
    "# define the number of temp repeats\n",
    "reps = int(np.ceil(35/nda.shape[0]))\n",
    "print(reps)\n",
    "nda = np.tile(nda, (reps, 1,1,1))\n",
    "print(nda.shape)\n",
    "METADATA_FILE = config.get('DF_META', '/mnt/ssd/data/gcn/02_imported_4D_unfiltered/SAx_3D_dicomTags_phase')\n",
    "df = pd.read_csv(METADATA_FILE)\n",
    "DF_METADATA = df[['patient', 'ED#', 'MS#', 'ES#', 'PF#', 'MD#']]\n",
    "\n",
    "\n",
    "patient_str = re.search('-(.{8})_', x).group(1).upper()\n",
    "ind = DF_METADATA[DF_METADATA.patient.str.contains(patient_str)][['ED#', 'MS#', 'ES#', 'PF#', 'MD#']]\n",
    "indices = ind.values[0].astype(int) -1\n",
    "onehot = np.zeros((indices.size, len(model_inputs)))\n",
    "onehot[np.arange(indices.size), indices] = 1\n",
    "print(onehot.shape)\n",
    "onehot = np.tile(onehot, (1,reps))[]\n",
    "print(onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad51496f3daf48f3a986b11ba4b63ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='', description='search_str'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def search_p_in_df(search_str = ''):\n",
    "    return DF_METADATA[DF_METADATA['patient'].str.contains(search_str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:16,586 INFO Create DataGenerator\n",
      "2021-02-12 15:06:16,587 INFO Datagenerator created with: \n",
      " shape: [10, 64, 64]\n",
      " spacing: [10, 4, 4]\n",
      " batchsize: 6\n",
      " Scaler: MinMax\n",
      " Images: 278 \n",
      " Augment: True \n",
      " Thread workers: 6\n",
      "2021-02-12 15:06:16,587 INFO Data will be augmented (shift,scale and rotate) with albumentation\n",
      "2021-02-12 15:06:16,602 INFO [0.2  0.25 0.3  0.35 0.4  1.   0.4  0.35 0.3  0.25 0.2 ]\n",
      "2021-02-12 15:06:16,603 INFO Create DataGenerator\n",
      "2021-02-12 15:06:16,605 INFO Datagenerator created with: \n",
      " shape: [10, 64, 64]\n",
      " spacing: [10, 4, 4]\n",
      " batchsize: 6\n",
      " Scaler: MinMax\n",
      " Images: 278 \n",
      " Augment: False \n",
      " Thread workers: 6\n",
      "2021-02-12 15:06:16,605 INFO No augmentation\n",
      "2021-02-12 15:06:16,619 INFO [0.2  0.25 0.3  0.35 0.4  1.   0.4  0.35 0.3  0.25 0.2 ]\n"
     ]
    }
   ],
   "source": [
    "# initialise a generator with these files\n",
    "# logging.getLogger().setLevel(logging.INFO)\n",
    "from src.data.Generators import PhaseRegressionGenerator\n",
    "#config['SHUFFLE'] = False\n",
    "#config['AUGMENT'] = False\n",
    "config['RESAMPLE'] = True\n",
    "batch_generator = PhaseRegressionGenerator(images, images, config=config)\n",
    "val_config = config.copy()\n",
    "val_config['AUGMENT'] = False\n",
    "validation_generator = PhaseRegressionGenerator(images, images , config=val_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce273ad979ac414ca280e43db3be4e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=23, description='batch', max=46), IntSlider(value=2, description='im', mâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualise one batch\n",
    "@interact_manual\n",
    "def select_image_in_batch(batch = (0,len(batch_generator), 1), \n",
    "                          im = (0,BATCHSIZE- 1, 1), \n",
    "                          slice_n=(1,11), \n",
    "                          save=False, \n",
    "                          filepath='data/temp/', \n",
    "                          filename='temp_x.npy',\n",
    "                         show_=True):\n",
    "    \n",
    "    import time\n",
    "    global inputs, outputs\n",
    "    t1 = time.time()\n",
    "    inputs, outputs = batch_generator.__getitem__(batch)\n",
    "    logging.info('Preprocessing took: {:0.3f}'.format(time.time() - t1))\n",
    "    print(inputs.shape, outputs.shape)\n",
    "    print('selected batch : ' + str(batch))\n",
    "    if show_:\n",
    "    \n",
    "        selected_input = inputs[im]\n",
    "        selected_output = outputs[im]\n",
    "\n",
    "        logging.debug('pad: \\n{}'.format(selected_output))\n",
    "\n",
    "        list(map(lambda x: show_2D_or_3D(img=x, interpol='bilinear',dpi=100,f_size=(5,5)), selected_input[::slice_n]))\n",
    "        plt.show()\n",
    "        info('-'*100)\n",
    "        #list(map(lambda x: show_2D_or_3D(img=x[::slice_n], interpol='bilinear',dpi=100,f_size=(5,5)), selected_output))\n",
    "\n",
    "        \"\"\"\n",
    "            show_2D_or_3D(x[im], y[im], interpol='bilinear',dpi=100,f_size=(5,5))\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        plt.hist(selected_input.flatten(), bins=np.linspace(0.1,1,20))\n",
    "        plt.show()\n",
    "    if save:\n",
    "        ensure_dir(filepath)\n",
    "        np.save(os.path.join(filepath, filename), x[im])\n",
    "        logging.info('saved to {}'.format(os.path.join(filepath, filename)))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:30,837 INFO Preprocessing took: 1.078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:31,554 INFO Preprocessing took: 0.717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:32,650 INFO Preprocessing took: 1.096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:33,455 INFO Preprocessing took: 0.805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:34,503 INFO Preprocessing took: 1.047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 4\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:35,570 INFO Preprocessing took: 1.066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:36,337 INFO Preprocessing took: 0.767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 6\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:37,305 INFO Preprocessing took: 0.967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 7\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:37,854 INFO Preprocessing took: 0.549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 8\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:38,834 INFO Preprocessing took: 0.979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 9\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:39,507 INFO Preprocessing took: 0.672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 10\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:40,153 INFO Preprocessing took: 0.646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 11\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:40,810 INFO Preprocessing took: 0.657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 12\n",
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:41,727 INFO Preprocessing took: 0.916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 13\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:42,404 INFO Preprocessing took: 0.676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 14\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:43,064 INFO Preprocessing took: 0.660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 15\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:44,224 INFO Preprocessing took: 1.159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 16\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:44,992 INFO Preprocessing took: 0.768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 17\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:46,033 INFO Preprocessing took: 1.041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 18\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:46,763 INFO Preprocessing took: 0.729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 19\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:47,782 INFO Preprocessing took: 1.019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 20\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:48,845 INFO Preprocessing took: 1.063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 21\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:49,559 INFO Preprocessing took: 0.714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 22\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:50,110 INFO Preprocessing took: 0.550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 23\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:50,877 INFO Preprocessing took: 0.766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 24\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:51,652 INFO Preprocessing took: 0.774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 25\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:52,555 INFO Preprocessing took: 0.903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 26\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:53,459 INFO Preprocessing took: 0.903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 27\n",
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:54,312 INFO Preprocessing took: 0.853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 28\n",
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:54,917 INFO Preprocessing took: 0.604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 29\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:55,743 INFO Preprocessing took: 0.826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:56,481 INFO Preprocessing took: 0.738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 31\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:57,355 INFO Preprocessing took: 0.874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 32\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:58,023 INFO Preprocessing took: 0.667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 33\n",
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:58,908 INFO Preprocessing took: 0.885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 34\n",
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:06:59,436 INFO Preprocessing took: 0.528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 35\n",
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:07:00,667 INFO Preprocessing took: 1.230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 36\n",
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:07:01,365 INFO Preprocessing took: 0.697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 37\n",
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:07:02,173 INFO Preprocessing took: 0.808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 38\n",
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:07:02,850 INFO Preprocessing took: 0.676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 39\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:07:03,907 INFO Preprocessing took: 1.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 40\n",
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:07:04,771 INFO Preprocessing took: 0.864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 41\n",
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:07:05,599 INFO Preprocessing took: 0.828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 42\n",
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:07:06,800 INFO Preprocessing took: 1.200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 43\n",
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:07:07,716 INFO Preprocessing took: 0.916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 44\n",
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 15:07:08,581 INFO Preprocessing took: 0.865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 35, 10, 64, 64, 1) (6, 35, 6)\n",
      "selected batch : 45\n"
     ]
    }
   ],
   "source": [
    "for b in range(len(batch_generator)):\n",
    "    print(b)\n",
    "    select_image_in_batch(batch=b, slice_n=5, show_=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2, 16, 16, 128)\n",
      "gap elem 0\n",
      "(None, 128)\n",
      "concat all\n",
      "(None, 35, 128)\n",
      "conv1d 256, 5, 2\n",
      "(None, 35, 32)\n",
      "(None, 35, 32)\n",
      "(None, 35, 6)\n"
     ]
    }
   ],
   "source": [
    "from src.models.Models import create_PhaseRegressionModel\n",
    "model = create_PhaseRegressionModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"PhaseRegressionModel\"\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      "input_2 (InputLayer)                             [(None, 35, 10, 64, 64, 1)]      0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_unstack_1 (TensorFlowOpLayer)        [(None, 10, 64, 64, 1), (None, 1 0                 input_2[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv_encoder_1 (ConvEncoder)                     ((None, 2, 16, 16, 128), [(None, 858400            tf_op_layer_unstack_1[0][0]                       \n",
      "                                                                                                    tf_op_layer_unstack_1[0][1]                       \n",
      "                                                                                                    tf_op_layer_unstack_1[0][2]                       \n",
      "                                                                                                    tf_op_layer_unstack_1[0][3]                       \n",
      "                                                                                                    tf_op_layer_unstack_1[0][4]                       \n",
      "                                                                                                    tf_op_layer_unstack_1[0][5]                       \n",
      "                                                                                                    tf_op_layer_unstack_1[0][6]                       \n",
      "                                                                                                    tf_op_layer_unstack_1[0][7]                       \n",
      "                                                                                                    tf_op_layer_unstack_1[0][8]                       \n",
      "                                                                                                    tf_op_layer_unstack_1[0][9]                       \n",
      "                                                                                                    tf_op_layer_unstack_1[0][10]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][11]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][12]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][13]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][14]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][15]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][16]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][17]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][18]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][19]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][20]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][21]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][22]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][23]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][24]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][25]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][26]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][27]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][28]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][29]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][30]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][31]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][32]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][33]                      \n",
      "                                                                                                    tf_op_layer_unstack_1[0][34]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "global_average_pooling3d_1 (GlobalAveragePooling (None, 128)                      0                 conv_encoder_1[0][0]                              \n",
      "                                                                                                    conv_encoder_1[1][0]                              \n",
      "                                                                                                    conv_encoder_1[2][0]                              \n",
      "                                                                                                    conv_encoder_1[3][0]                              \n",
      "                                                                                                    conv_encoder_1[4][0]                              \n",
      "                                                                                                    conv_encoder_1[5][0]                              \n",
      "                                                                                                    conv_encoder_1[6][0]                              \n",
      "                                                                                                    conv_encoder_1[7][0]                              \n",
      "                                                                                                    conv_encoder_1[8][0]                              \n",
      "                                                                                                    conv_encoder_1[9][0]                              \n",
      "                                                                                                    conv_encoder_1[10][0]                             \n",
      "                                                                                                    conv_encoder_1[11][0]                             \n",
      "                                                                                                    conv_encoder_1[12][0]                             \n",
      "                                                                                                    conv_encoder_1[13][0]                             \n",
      "                                                                                                    conv_encoder_1[14][0]                             \n",
      "                                                                                                    conv_encoder_1[15][0]                             \n",
      "                                                                                                    conv_encoder_1[16][0]                             \n",
      "                                                                                                    conv_encoder_1[17][0]                             \n",
      "                                                                                                    conv_encoder_1[18][0]                             \n",
      "                                                                                                    conv_encoder_1[19][0]                             \n",
      "                                                                                                    conv_encoder_1[20][0]                             \n",
      "                                                                                                    conv_encoder_1[21][0]                             \n",
      "                                                                                                    conv_encoder_1[22][0]                             \n",
      "                                                                                                    conv_encoder_1[23][0]                             \n",
      "                                                                                                    conv_encoder_1[24][0]                             \n",
      "                                                                                                    conv_encoder_1[25][0]                             \n",
      "                                                                                                    conv_encoder_1[26][0]                             \n",
      "                                                                                                    conv_encoder_1[27][0]                             \n",
      "                                                                                                    conv_encoder_1[28][0]                             \n",
      "                                                                                                    conv_encoder_1[29][0]                             \n",
      "                                                                                                    conv_encoder_1[30][0]                             \n",
      "                                                                                                    conv_encoder_1[31][0]                             \n",
      "                                                                                                    conv_encoder_1[32][0]                             \n",
      "                                                                                                    conv_encoder_1[33][0]                             \n",
      "                                                                                                    conv_encoder_1[34][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "tf_op_layer_stack_1 (TensorFlowOpLayer)          [(None, 35, 128)]                0                 global_average_pooling3d_1[0][0]                  \n",
      "                                                                                                    global_average_pooling3d_1[1][0]                  \n",
      "                                                                                                    global_average_pooling3d_1[2][0]                  \n",
      "                                                                                                    global_average_pooling3d_1[3][0]                  \n",
      "                                                                                                    global_average_pooling3d_1[4][0]                  \n",
      "                                                                                                    global_average_pooling3d_1[5][0]                  \n",
      "                                                                                                    global_average_pooling3d_1[6][0]                  \n",
      "                                                                                                    global_average_pooling3d_1[7][0]                  \n",
      "                                                                                                    global_average_pooling3d_1[8][0]                  \n",
      "                                                                                                    global_average_pooling3d_1[9][0]                  \n",
      "                                                                                                    global_average_pooling3d_1[10][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[11][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[12][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[13][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[14][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[15][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[16][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[17][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[18][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[19][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[20][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[21][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[22][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[23][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[24][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[25][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[26][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[27][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[28][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[29][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[30][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[31][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[32][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[33][0]                 \n",
      "                                                                                                    global_average_pooling3d_1[34][0]                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)                                (None, 35, 32)                   4128              tf_op_layer_stack_1[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNormalization)      (None, 35, 32)                   128               conv1d_3[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)                                (None, 35, 32)                   3104              batch_normalization_13[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)                                (None, 35, 6)                    582               conv1d_4[0][0]                                    \n",
      "======================================================================================================================================================\n",
      "Total params: 866,342\n",
      "Trainable params: 866,278\n",
      "Non-trainable params: 64\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "46/46 [==============================] - 87s 2s/step - loss: 0.1018 - categorical_accuracy: 0.4596 - accuracy: 0.3919 - val_loss: 0.2580 - val_categorical_accuracy: 0.1513 - val_accuracy: 0.3759 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "46/46 [==============================] - 83s 2s/step - loss: 0.0360 - categorical_accuracy: 0.5268 - accuracy: 0.4201 - val_loss: 0.2239 - val_categorical_accuracy: 0.2032 - val_accuracy: 0.3923 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "46/46 [==============================] - 85s 2s/step - loss: 0.0337 - categorical_accuracy: 0.5350 - accuracy: 0.4299 - val_loss: 0.4788 - val_categorical_accuracy: 0.2479 - val_accuracy: 0.3556 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "46/46 [==============================] - 86s 2s/step - loss: 0.0319 - categorical_accuracy: 0.5378 - accuracy: 0.4320 - val_loss: 0.6070 - val_categorical_accuracy: 0.2652 - val_accuracy: 0.3314 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "46/46 [==============================] - 84s 2s/step - loss: 0.0315 - categorical_accuracy: 0.5550 - accuracy: 0.4327 - val_loss: 0.7412 - val_categorical_accuracy: 0.4409 - val_accuracy: 0.3026 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "46/46 [==============================] - 85s 2s/step - loss: 0.0303 - categorical_accuracy: 0.5718 - accuracy: 0.4341 - val_loss: 1.0786 - val_categorical_accuracy: 0.4352 - val_accuracy: 0.2872 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "46/46 [==============================] - 84s 2s/step - loss: 0.0300 - categorical_accuracy: 0.5749 - accuracy: 0.4338 - val_loss: 0.7699 - val_categorical_accuracy: 0.4751 - val_accuracy: 0.2999 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "46/46 [==============================] - 85s 2s/step - loss: 0.0294 - categorical_accuracy: 0.5841 - accuracy: 0.4338 - val_loss: 1.0373 - val_categorical_accuracy: 0.4899 - val_accuracy: 0.2588 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "46/46 [==============================] - 83s 2s/step - loss: 0.0293 - categorical_accuracy: 0.5883 - accuracy: 0.4330 - val_loss: 0.7987 - val_categorical_accuracy: 0.5302 - val_accuracy: 0.2644 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "46/46 [==============================] - 84s 2s/step - loss: 0.0293 - categorical_accuracy: 0.5970 - accuracy: 0.4335 - val_loss: 0.9826 - val_categorical_accuracy: 0.5218 - val_accuracy: 0.2790 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "46/46 [==============================] - 86s 2s/step - loss: 0.0290 - categorical_accuracy: 0.6040 - accuracy: 0.4337 - val_loss: 0.7574 - val_categorical_accuracy: 0.5325 - val_accuracy: 0.3010 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "46/46 [==============================] - 85s 2s/step - loss: 0.0286 - categorical_accuracy: 0.6095 - accuracy: 0.4349 - val_loss: 0.4710 - val_categorical_accuracy: 0.5354 - val_accuracy: 0.3427 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "46/46 [==============================] - 85s 2s/step - loss: 0.0284 - categorical_accuracy: 0.6102 - accuracy: 0.4342 - val_loss: 0.4079 - val_categorical_accuracy: 0.5189 - val_accuracy: 0.3654 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "46/46 [==============================] - 85s 2s/step - loss: 0.0282 - categorical_accuracy: 0.6214 - accuracy: 0.4342 - val_loss: 0.2768 - val_categorical_accuracy: 0.4715 - val_accuracy: 0.3315 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "46/46 [==============================] - 84s 2s/step - loss: 0.0275 - categorical_accuracy: 0.6356 - accuracy: 0.4350 - val_loss: 38632.7148 - val_categorical_accuracy: 0.3598 - val_accuracy: 0.3987 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "46/46 [==============================] - 84s 2s/step - loss: 0.0267 - categorical_accuracy: 0.6476 - accuracy: 0.4377 - val_loss: 5613.4922 - val_categorical_accuracy: 0.3772 - val_accuracy: 0.4475 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "46/46 [==============================] - 83s 2s/step - loss: 0.0259 - categorical_accuracy: 0.6714 - accuracy: 0.4411 - val_loss: 9411.8350 - val_categorical_accuracy: 0.3618 - val_accuracy: 0.4459 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "46/46 [==============================] - 84s 2s/step - loss: 0.0271 - categorical_accuracy: 0.6361 - accuracy: 0.4393 - val_loss: 1.7452 - val_categorical_accuracy: 0.4238 - val_accuracy: 0.3274 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "46/46 [==============================] - 84s 2s/step - loss: 0.0267 - categorical_accuracy: 0.6499 - accuracy: 0.4375 - val_loss: 0.9030 - val_categorical_accuracy: 0.4967 - val_accuracy: 0.4227 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "46/46 [==============================] - 88s 2s/step - loss: 0.0442 - categorical_accuracy: 0.5445 - accuracy: 0.4404 - val_loss: 12872.0459 - val_categorical_accuracy: 0.1863 - val_accuracy: 0.3129 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "46/46 [==============================] - 87s 2s/step - loss: 0.0338 - categorical_accuracy: 0.5733 - accuracy: 0.4330 - val_loss: 55750.1758 - val_categorical_accuracy: 0.2315 - val_accuracy: 0.2747 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0316 - categorical_accuracy: 0.5944 - accuracy: 0.4122\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "46/46 [==============================] - 84s 2s/step - loss: 0.0316 - categorical_accuracy: 0.5944 - accuracy: 0.4122 - val_loss: 51494.4102 - val_categorical_accuracy: 0.2844 - val_accuracy: 0.2374 - lr: 1.0000e-04\n",
      "Epoch 23/200\n",
      "46/46 [==============================] - 83s 2s/step - loss: 0.0299 - categorical_accuracy: 0.6176 - accuracy: 0.3994 - val_loss: 56855.8320 - val_categorical_accuracy: 0.2749 - val_accuracy: 0.2349 - lr: 1.0000e-04\n",
      "Epoch 24/200\n",
      "46/46 [==============================] - 81s 2s/step - loss: 0.0295 - categorical_accuracy: 0.6259 - accuracy: 0.3982 - val_loss: 60893.0859 - val_categorical_accuracy: 0.2835 - val_accuracy: 0.2298 - lr: 1.0000e-04\n",
      "Epoch 25/200\n",
      "46/46 [==============================] - 84s 2s/step - loss: 0.0297 - categorical_accuracy: 0.6226 - accuracy: 0.4001 - val_loss: 68182.7578 - val_categorical_accuracy: 0.4363 - val_accuracy: 0.2291 - lr: 1.0000e-04\n",
      "Epoch 26/200\n",
      "46/46 [==============================] - 83s 2s/step - loss: 0.0302 - categorical_accuracy: 0.6225 - accuracy: 0.4002 - val_loss: 71105.6797 - val_categorical_accuracy: 0.4255 - val_accuracy: 0.2261 - lr: 1.0000e-04\n",
      "Epoch 27/200\n",
      "46/46 [==============================] - 84s 2s/step - loss: 0.0297 - categorical_accuracy: 0.6251 - accuracy: 0.3974 - val_loss: 72242.7891 - val_categorical_accuracy: 0.4633 - val_accuracy: 0.2322 - lr: 1.0000e-04\n",
      "Epoch 00027: early stopping\n"
     ]
    }
   ],
   "source": [
    "initial_epoch = 0\n",
    "\n",
    "results = model.fit(\n",
    "    x=batch_generator,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    epochs=200,\n",
    "    callbacks = get_callbacks(config, validation_generator),\n",
    "    steps_per_epoch = len(batch_generator),\n",
    "    initial_epoch=initial_epoch,\n",
    "    max_queue_size=20,\n",
    "    workers=2,\n",
    "    use_multiprocessing=False,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = np.eye(3)\n",
    "print(temp.shape)\n",
    "plt.imshow(temp)\n",
    "plt.show()\n",
    "temp2 = np.zeros((1,5))\n",
    "print(temp2.shape)\n",
    "plt.imshow(temp2)\n",
    "plt.show()\n",
    "\n",
    "temp3 = np.tile(temp2, (2,1))\n",
    "print(temp3.shape)\n",
    "plt.imshow(temp3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = outputs[0][:]\n",
    "plt.imshow(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.concatenate([temp, temp])\n",
    "print(t.shape)\n",
    "first, second = np.split(t, indices_or_sections=2)\n",
    "print(first.shape)\n",
    "temp = np.maximum(first,second)\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonempty_timesteps = (np.sum(temp,axis=1)==0).astype(int)\n",
    "nonempty_timesteps.shape\n",
    "nonempty_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonempty_timesteps[:,None].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([temp, nonempty_timesteps[:,None]], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = outputs[0][:]\n",
    "print(temp.shape)\n",
    "print(temp)\n",
    "print(temp.sum(axis=0))\n",
    "print(temp.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = np.array([[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    " [0,0,0,1,0,0,0,0,0,0,0,0,0,0,0],\n",
    " [0,0,0,0,0,0,0,1,0,0,0,0,0,0,0],\n",
    " [0,0,0,0,0,0,0,0,0,0,0,1,0,0,0],\n",
    " [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_t = onehot.T\n",
    "onehot_t.shape\n",
    "onehot_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(onehot, axis=1))\n",
    "print(np.argmax(onehot_t, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the phases j\n",
    "# linspace from i to i+1 from indices\n",
    "temp = onehot_t[:,0].astype(float)\n",
    "i = 0\n",
    "j = 3 + 1\n",
    "temp[i:j] = np.linspace(i,j,j-i)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_t = onehot_t.astype(float)\n",
    "indices = np.argmax(onehot_t, axis=0)\n",
    "for i in range(onehot_t.shape[1]) :\n",
    "    start = indices[i]\n",
    "    # make it a ring\n",
    "    second = (i+1)%len(indices)\n",
    "    end = indices[second]\n",
    "    onehot_t[start:end,i] = np.linspace(1,0,int(end-start))\n",
    "onehot_t\n",
    "             \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth the one-hot vectors along the indexes\n",
    "# each phase has a small range of valid indexes with a convolved smoothing\n",
    "import sys\n",
    "temp = np.copy(outputs[0])\n",
    "kernelsize = 5\n",
    "lower = 0.1\n",
    "upper = 0.5\n",
    "# create a kernel with linearly increasing, than one, than decreasing smoothing\n",
    "kernel = np.concatenate([np.linspace(lower,upper,kernelsize//2), [1], np.linspace(upper,lower,kernelsize//2)])\n",
    "print('Kernel: {}'.format(kernel))\n",
    "for idx in range(temp.shape[0]):\n",
    "    print(temp[idx])\n",
    "    smoothed = np.convolve(temp[idx],kernel, mode='same')\n",
    "    print('convolved: {}'.format(smoothed))\n",
    "    smoothed = smoothed/(sum(smoothed) + sys.float_info.epsilon)\n",
    "    print('normalised: {}'.format(smoothed))\n",
    "    temp[idx] = smoothed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(temp.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load phase indicies from the df\n",
    "print(len(images))\n",
    "patient_temp = images[0]\n",
    "# search for the 8 digits of the patient ID which should have a underscore in before and than a minus\n",
    "patient_str = re.search('-(.{8})_', patient_temp).group(1)\n",
    "df = pd.read_csv('/mnt/ssd/data/gcn/02_imported_4D_unfiltered_old/SAx_3D_dicomTags_phase')\n",
    "df = df[['patient', 'ED#', 'MS#', 'ES#', 'PF#', 'MD#']]\n",
    "df[df.patient.str.contains(patient_str)][['ED#', 'MS#', 'ES#', 'PF#', 'MD#']].values[0].astype(int) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "a = get_patient(patient_temp)\n",
    "\n",
    "re.search('-(.{8})_', patient_temp).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "temp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "np.mean(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(-1,1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcmr",
   "language": "python",
   "name": "dcmr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0ead44ab91e24e12a083fa4fd4e4bb3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "TextModel",
      "state": {
       "description": "filename",
       "layout": "IPY_MODEL_29c39bc7c2b34517bac644867546ac2a",
       "style": "IPY_MODEL_6a7e8d480f9a46a0887186952d008f25",
       "value": "temp_x.npy"
      }
     },
     "11b5e87b9ae54700a782745526267686": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "175a8ab3420f49ac8846b0b95e03d1f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2344bef3b0c8478da555aef2138f99df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "29c39bc7c2b34517bac644867546ac2a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "373eaa6c1a2b44b7a00e5c31a71da204": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "CheckboxModel",
      "state": {
       "description": "show_",
       "disabled": false,
       "layout": "IPY_MODEL_11b5e87b9ae54700a782745526267686",
       "style": "IPY_MODEL_4e4d6f5a19d04cd6bbddf42a8adc9acd",
       "value": true
      }
     },
     "4e4d6f5a19d04cd6bbddf42a8adc9acd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "54d4e26363ca43cc810c9b4d4916c64e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5e574aff32bc4b05bbaf30340d27300d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "69e4b12439c74c45aa412d7657aa76ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6a7e8d480f9a46a0887186952d008f25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "74b94def2be04249adb743cf0c2dd55f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "TextModel",
      "state": {
       "description": "filepath",
       "layout": "IPY_MODEL_f4574daa8c574dfbb3e73bd995a7fe84",
       "style": "IPY_MODEL_69e4b12439c74c45aa412d7657aa76ab",
       "value": "data/temp/"
      }
     },
     "766fdc8d47ea42c9b3e5a0bad398519b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "779e789625414449bb26343c2be738de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "description": "batch",
       "layout": "IPY_MODEL_766fdc8d47ea42c9b3e5a0bad398519b",
       "max": 46,
       "style": "IPY_MODEL_d8dbd0de9bdd4bbba2bb7ac5dc27d585",
       "value": 23
      }
     },
     "96477b70e05543e79ec28bc1a0b1f552": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9901db817a01475bbde42c6132496091": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "description": "im",
       "layout": "IPY_MODEL_dc62f7517ad7468d90077bee0bda82fd",
       "max": 5,
       "style": "IPY_MODEL_96477b70e05543e79ec28bc1a0b1f552",
       "value": 2
      }
     },
     "9bb04b191ff041f9811ccd2be3c2c333": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_d88e46a5b1bc4441b16570a69ff061dd"
      }
     },
     "b8c5a06426f54ff9841fbbc71fd76f48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Run Interact",
       "layout": "IPY_MODEL_54d4e26363ca43cc810c9b4d4916c64e",
       "style": "IPY_MODEL_cd8e2a42548e4687b049871423dca64e"
      }
     },
     "ba8d1b7375db42f58b966d3d54e47c4d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bd0d746588c14c62a6f829ace6389d94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "CheckboxModel",
      "state": {
       "description": "save",
       "disabled": false,
       "layout": "IPY_MODEL_ba8d1b7375db42f58b966d3d54e47c4d",
       "style": "IPY_MODEL_5e574aff32bc4b05bbaf30340d27300d",
       "value": false
      }
     },
     "c62f61f83577488e8d2b70a22f8bccf2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "description": "slice_n",
       "layout": "IPY_MODEL_175a8ab3420f49ac8846b0b95e03d1f3",
       "max": 11,
       "min": 1,
       "style": "IPY_MODEL_eb74dad736ab44349fc02a2f9065539b",
       "value": 6
      }
     },
     "cd8e2a42548e4687b049871423dca64e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "ce273ad979ac414ca280e43db3be4e8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [
        "widget-interact"
       ],
       "children": [
        "IPY_MODEL_779e789625414449bb26343c2be738de",
        "IPY_MODEL_9901db817a01475bbde42c6132496091",
        "IPY_MODEL_c62f61f83577488e8d2b70a22f8bccf2",
        "IPY_MODEL_bd0d746588c14c62a6f829ace6389d94",
        "IPY_MODEL_74b94def2be04249adb743cf0c2dd55f",
        "IPY_MODEL_0ead44ab91e24e12a083fa4fd4e4bb3c",
        "IPY_MODEL_373eaa6c1a2b44b7a00e5c31a71da204",
        "IPY_MODEL_b8c5a06426f54ff9841fbbc71fd76f48",
        "IPY_MODEL_9bb04b191ff041f9811ccd2be3c2c333"
       ],
       "layout": "IPY_MODEL_2344bef3b0c8478da555aef2138f99df"
      }
     },
     "d88e46a5b1bc4441b16570a69ff061dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d8dbd0de9bdd4bbba2bb7ac5dc27d585": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "dc62f7517ad7468d90077bee0bda82fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "eb74dad736ab44349fc02a2f9065539b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f4574daa8c574dfbb3e73bd995a7fe84": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
