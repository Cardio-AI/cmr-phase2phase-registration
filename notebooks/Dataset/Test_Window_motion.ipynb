{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search for root_dir and set working directory\n",
      "Working directory set to: /mnt/ssd/git/dynamic-cmr-models\n",
      "['/gpu:0', '/gpu:1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 11:58:31,501 INFO -------------------- Start --------------------\n",
      "2021-05-21 11:58:31,502 INFO Working directory: /mnt/ssd/git/dynamic-cmr-models.\n",
      "2021-05-21 11:58:31,502 INFO Log file: ./logs/temp/windowmotion.log\n",
      "2021-05-21 11:58:31,502 INFO Log level for console: INFO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__K': None, 'GPU_IDS': '0,1', 'GPUS': ['/gpu:0', '/gpu:1'], 'SEED': 42, 'EXPERIMENT': 'temp/windowmotion', 'EXPERIMENTS_ROOT': 'exp/', 'EXP_PATH': 'exp/temp/windowmotion/2021-05-21_11_58', 'MODEL_PATH': 'exp/temp/windowmotion/2021-05-21_11_58/model', 'TENSORBOARD_PATH': 'exp/temp/windowmotion/2021-05-21_11_58/tensorboard_logs', 'CONFIG_PATH': 'exp/temp/windowmotion/2021-05-21_11_58/config', 'HISTORY_PATH': 'exp/temp/windowmotion/2021-05-21_11_58/history', 'DATA_PATH_SAX': '/mnt/ssd/data/gcn/02_imported_4D_unfiltered/sax/', 'DF_FOLDS': '/mnt/ssd/data/gcn/metadata/df_kfold.csv', 'DF_META': '/mnt/ssd/data/gcn/metadata/SAx_3D_dicomTags_phase', 'FOLD': 0, 'BATCHSIZE': 2, 'GENERATOR_WORKER': 2, 'DIM': [64, 128, 128], 'SPACING': [2, 2, 2], 'T_SPACING': 55, 'DEPTH': 3, 'FILTERS': 16, 'M_POOL': [2, 2, 2], 'F_SIZE': [3, 3, 3], 'MASK_VALUES': [1, 2, 3], 'MASK_CLASSES': 3, 'MASKING_IMAGE': False, 'MASKING_VALUES': [1, 2, 3], 'BORDER_MODE': 4, 'IMG_INTERPOLATION': 1, 'MSK_INTERPOLATION': 0, 'AUGMENT': True, 'AUGMENT_PROB': 0.8, 'SHUFFLE': True, 'RESAMPLE': True, 'AUGMENT_TEMP': False, 'AUGMENT_TEMP_RANGE': (-2, 2), 'RESAMPLE_T': True, 'HIST_MATCHING': False, 'SCALER': 'Standard', 'TENSORBOARD_LOG_DIR': 'exp/temp/windowmotion/2021-05-21_11_58/tensorboard_logs'}\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------define logging and working directory\n",
    "from ProjectRoot import change_wd_to_project_root\n",
    "change_wd_to_project_root()\n",
    "\n",
    "from src.utils.Tensorflow_helper import choose_gpu_by_id\n",
    "# ------------------------------------------define GPU id/s to use\n",
    "GPU_IDS = '0,1'\n",
    "GPUS = choose_gpu_by_id(GPU_IDS)\n",
    "print(GPUS)\n",
    "\n",
    "# this should import glob, os, and many other standard libs\n",
    "from src.utils.Notebook_imports import *\n",
    "\n",
    "# local imports\n",
    "from src.utils.Utils_io import Console_and_file_logger, init_config\n",
    "from src.visualization.Visualize import show_2D_or_3D\n",
    "\n",
    "# import external libs\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------jupyter magic config\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "EXPERIMENT = 'temp/windowmotion'\n",
    "timestemp = str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M\")) # ad a timestep to each project to make repeated experiments unique\n",
    "\n",
    "EXPERIMENTS_ROOT = 'exp/'\n",
    "EXP_PATH = os.path.join(EXPERIMENTS_ROOT, EXPERIMENT, timestemp)\n",
    "MODEL_PATH = os.path.join(EXP_PATH, 'model', )\n",
    "TENSORBOARD_PATH = os.path.join(EXP_PATH, 'tensorboard_logs')\n",
    "CONFIG_PATH = os.path.join(EXP_PATH,'config')\n",
    "HISTORY_PATH = os.path.join(EXP_PATH, 'history')\n",
    "ensure_dir(MODEL_PATH)\n",
    "ensure_dir(TENSORBOARD_PATH)\n",
    "ensure_dir(CONFIG_PATH)\n",
    "ensure_dir(HISTORY_PATH)\n",
    "\n",
    "# define the input data paths and fold \n",
    "# first to the 4D Nrrd files, \n",
    "# second to a dataframe with a mapping of the Fold-number\n",
    "# Finally the path to the metadata\n",
    "DATA_PATH_SAX = '/mnt/ssd/data/gcn/02_imported_4D_unfiltered/sax/'\n",
    "DF_FOLDS = '/mnt/ssd/data/gcn/metadata/df_kfold.csv'\n",
    "DF_META = '/mnt/ssd/data/gcn/metadata/SAx_3D_dicomTags_phase'\n",
    "FOLD = 0\n",
    "\n",
    "# ------------------------------------------generator hyperparameters\n",
    "SEED = 42 # define a seed for the generator shuffle\n",
    "BATCHSIZE = 2 # 32, 64, 24, 16, 1 for 3D use: 4\n",
    "GENERATOR_WORKER = BATCHSIZE # if not set, use batchsize\n",
    "DIM = [64, 128, 128] # network input params for spacing of 3, (z,y,x)\n",
    "SPACING = [2, 2, 2] # if resample, resample to this spacing, (z,y,x)\n",
    "T_SPACING = 55\n",
    "DEPTH = 3 # depth of the encoder\n",
    "FILTERS = 16 # initial number of filters, will be doubled after each downsampling block\n",
    "M_POOL = [2, 2, 2]# size of max-pooling used for downsampling and upsampling\n",
    "F_SIZE = [3, 3, 3] # conv filter size\n",
    "# maybe we can drop this channel?\n",
    "#IMG_CHANNELS = 1 # Currently our model needs that image channel\n",
    "MASK_VALUES = [1, 2, 3]  #channel order: Background, RV, MYO, LV\n",
    "MASK_CLASSES = len(MASK_VALUES) # no of labels\n",
    "MASKING_IMAGE = False\n",
    "MASKING_VALUES = [1,2,3]\n",
    "BORDER_MODE = cv2.BORDER_REFLECT_101 # border mode for the data generation\n",
    "IMG_INTERPOLATION = cv2.INTER_LINEAR # image interpolation in the genarator\n",
    "MSK_INTERPOLATION = cv2.INTER_NEAREST # mask interpolation in the generator\n",
    "AUGMENT = True # a compose of 2D augmentation (grid distortion, 90degree rotation, brightness and shift)\n",
    "AUGMENT_PROB = 0.8\n",
    "SHUFFLE = True\n",
    "RESAMPLE = True\n",
    "AUGMENT_TEMP = False\n",
    "AUGMENT_TEMP_RANGE = (-2,2)\n",
    "RESAMPLE_T = True\n",
    "HIST_MATCHING = False\n",
    "SCALER = 'Standard' # MinMax Standard or Robust\n",
    "\n",
    "Console_and_file_logger(EXPERIMENT, logging.INFO)\n",
    "config = init_config(config=locals(), save=True)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 11:58:31,584 INFO no files found, try to load with clean.nrrd/mask.nrrd pattern\n",
      "2021-05-21 11:58:31,585 INFO searched in: /mnt/ssd/data/gcn/02_imported_4D_unfiltered/sax/\n",
      "2021-05-21 11:58:31,593 INFO Found 278 images/masks in /mnt/ssd/data/gcn/02_imported_4D_unfiltered/sax/\n",
      "2021-05-21 11:58:31,593 INFO Patients train: 209\n",
      "2021-05-21 11:58:31,604 INFO Selected 209 of 278 files with 209 of 279 patients for training fold 0\n",
      "2021-05-21 11:58:31,604 INFO SAX train CMR: 209, SAX train masks: 209\n",
      "2021-05-21 11:58:31,605 INFO SAX val CMR: 69, SAX val masks: 69\n"
     ]
    }
   ],
   "source": [
    "# Load SAX volumes\n",
    "from src.data.Dataset import get_trainings_files\n",
    "x_train_sax, y_train_sax, x_val_sax, y_val_sax =  get_trainings_files(data_path=DATA_PATH_SAX,path_to_folds_df=DF_FOLDS, fold=FOLD)\n",
    "logging.info('SAX train CMR: {}, SAX train masks: {}'.format(len(x_train_sax), len(y_train_sax)))\n",
    "logging.info('SAX val CMR: {}, SAX val masks: {}'.format(len(x_val_sax), len(y_val_sax)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 11:58:31,760 INFO Create DataGenerator\n",
      "2021-05-21 11:58:31,761 INFO Datagenerator created with: \n",
      " shape: [64, 128, 128]\n",
      " spacing: [2, 2, 2]\n",
      " batchsize: 2\n",
      " Scaler: Standard\n",
      " Images: 209 \n",
      " Augment: True \n",
      " Thread workers: 2\n",
      "2021-05-21 11:58:31,761 INFO Data will be augmented (shift,scale and rotate) with albumentation\n",
      "2021-05-21 11:58:31,775 INFO params of generator:\n",
      "2021-05-21 11:58:31,776 INFO [('MASKING_IMAGE', False), ('SINGLE_OUTPUT', False), ('MASKING_VALUES', [1, 2, 3]), ('DEBUG_MODE', False), ('SCALER', 'Standard'), ('AUGMENT', True), ('SHUFFLE', True), ('RESAMPLE', True), ('SPACING', [2, 2, 2]), ('SEED', 42), ('DIM', [64, 128, 128]), ('BATCHSIZE', 2), ('MASK_VALUES', [1, 2, 3]), ('N_CLASSES', 3), ('MAX_WORKERS', 2), ('T_SPACING', 55), ('PHASES', 5), ('HIST_MATCHING', False), ('IMG_INTERPOLATION', 1), ('MSK_INTERPOLATION', 0), ('AUGMENT_TEMP', False), ('RESAMPLE_T', True), ('ISACDC', False), ('METADATA_FILE', '/mnt/ssd/data/gcn/metadata/SAx_3D_dicomTags_phase')]\n",
      "2021-05-21 11:58:31,776 INFO Create DataGenerator\n",
      "2021-05-21 11:58:31,777 INFO Datagenerator created with: \n",
      " shape: [64, 128, 128]\n",
      " spacing: [2, 2, 2]\n",
      " batchsize: 2\n",
      " Scaler: Standard\n",
      " Images: 69 \n",
      " Augment: False \n",
      " Thread workers: 2\n",
      "2021-05-21 11:58:31,777 INFO No augmentation\n",
      "2021-05-21 11:58:31,790 INFO params of generator:\n",
      "2021-05-21 11:58:31,790 INFO [('MASKING_IMAGE', False), ('SINGLE_OUTPUT', False), ('MASKING_VALUES', [1, 2, 3]), ('DEBUG_MODE', False), ('SCALER', 'Standard'), ('AUGMENT', False), ('SHUFFLE', True), ('RESAMPLE', True), ('SPACING', [2, 2, 2]), ('SEED', 42), ('DIM', [64, 128, 128]), ('BATCHSIZE', 2), ('MASK_VALUES', [1, 2, 3]), ('N_CLASSES', 3), ('MAX_WORKERS', 2), ('T_SPACING', 55), ('PHASES', 5), ('HIST_MATCHING', False), ('IMG_INTERPOLATION', 1), ('MSK_INTERPOLATION', 0), ('AUGMENT_TEMP', False), ('RESAMPLE_T', True), ('ISACDC', False), ('METADATA_FILE', '/mnt/ssd/data/gcn/metadata/SAx_3D_dicomTags_phase')]\n"
     ]
    }
   ],
   "source": [
    "# initialise a generator with these files\n",
    "# logging.getLogger().setLevel(logging.INFO)\n",
    "from src.data.Generators import PhaseWindowGenerator\n",
    "config['AUGMENT'] = True\n",
    "config['RESAMPLE'] = True\n",
    "batch_generator = PhaseWindowGenerator(x_train_sax, x_train_sax, config=config)\n",
    "val_config = config.copy()\n",
    "val_config['AUGMENT'] = False\n",
    "val_config['AUGMENT_TEMP'] = False\n",
    "val_config['HIST_MATCHING'] = False\n",
    "validation_generator = PhaseWindowGenerator(x_val_sax, x_val_sax , config=val_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f22a59e350d4dc98421b7ed456d4a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=52, description='batch', max=104), IntSlider(value=0, description='im', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualise one batch\n",
    "@interact_manual\n",
    "def select_image_in_batch(batch = (0,len(batch_generator), 1), im = (0,BATCHSIZE- 1, 1), slice_n=(1,11), save=False, filepath='data/temp/', filename='temp_x.npy'):\n",
    "    \n",
    "    import time\n",
    "    global inputs, outputs\n",
    "    t1 = time.time()\n",
    "    inputs, outputs = batch_generator.__getitem__(batch)\n",
    "    if type(inputs)==list:inputs, outputs = inputs[0], outputs[0]\n",
    "    logging.info('Preprocessing took: {:0.3f}'.format(time.time() - t1))\n",
    "    print(inputs.shape, outputs.shape)\n",
    "    print('selected batch : ' + str(batch))\n",
    "    \n",
    "    selected_input = inputs[im]\n",
    "    selected_output = outputs[im]\n",
    "    \n",
    "    list(map(lambda x: show_2D_or_3D(img=x[::slice_n], interpol='bilinear',dpi=100,f_size=(5,5)), selected_input))\n",
    "    plt.show()\n",
    "    info('-'*100)\n",
    "    list(map(lambda y: show_2D_or_3D(img=y[::slice_n], interpol='bilinear',dpi=100,f_size=(5,5)), selected_output))\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(selected_input.flatten(), bins=np.linspace(0.1,1,20))\n",
    "    plt.show()\n",
    "    if save:\n",
    "        ensure_dir(filepath)\n",
    "        np.save(os.path.join(filepath, filename), x[im])\n",
    "        logging.info('saved to {}'.format(os.path.join(filepath, filename)))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7354dfe0a9349d9b9451812e23116e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=52, description='batch', max=104), IntSlider(value=0, description='im', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualise one batch\n",
    "@interact_manual\n",
    "def select_image_in_batch(batch = (0,len(batch_generator), 1), im = (0,BATCHSIZE- 1, 1), slice_n=(1,11), save=False, filepath='data/temp/', filename='temp_x.npy'):\n",
    "    \n",
    "    import time\n",
    "    global inputs, outputs\n",
    "    t1 = time.time()\n",
    "    inputs, outputs = batch_generator.__getitem__(batch)\n",
    "    if type(inputs)==list:inputs, outputs = inputs[0], outputs[0]\n",
    "    logging.info('Preprocessing took: {:0.3f}'.format(time.time() - t1))\n",
    "    print(inputs.shape, outputs.shape)\n",
    "    print('selected batch : ' + str(batch))\n",
    "    \n",
    "    selected_input = inputs[im]\n",
    "    selected_output = outputs[im]\n",
    "    \n",
    "    # plot the pre (t-1) and post (t+1) volume of each cardiac phase and the difference\n",
    "    _ = list(map(lambda x : show_two_timesteps(x),  zip(['ED#', 'MS#', 'ES#', 'PF#', 'MD#'],np.stack([selected_input, selected_output], axis=1))))\n",
    "\n",
    "    plt.hist(selected_input.flatten(), bins=np.linspace(0.1,1,20))\n",
    "    plt.show()\n",
    "    if save:\n",
    "        ensure_dir(filepath)\n",
    "        np.save(os.path.join(filepath, filename), x[im])\n",
    "        logging.info('saved to {}'.format(os.path.join(filepath, filename)))\n",
    "        \n",
    "def show_two_timesteps(x):\n",
    "    # x is a tuple of phase (string), ndarray with the following shape: 2,z,x,y --> first and second timestep of the motion window\n",
    "    p, x = x\n",
    "    inter, dpi, f_size = 'bilinear', 100, (5,5)\n",
    "    logging.info('Phase: {}'.format(p))\n",
    "    show_2D_or_3D(img=x[0], interpol=inter,dpi=dpi,f_size=f_size);plt.show()\n",
    "    show_2D_or_3D(img=x[1], interpol=inter,dpi=dpi,f_size=f_size);plt.show()\n",
    "    show_2D_or_3D(img=x[0] - x[1], interpol=None,dpi=dpi,f_size=f_size);plt.show()\n",
    "    logging.info(\"-\"*20)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using tensorflow, need to monkey patch\n",
      "tf.python.backend.slice overwritten by monkey patch\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 11:58:32,728 INFO Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 128, 128, 1)\n",
      "(None, 64, 128, 128, 1)\n",
      "WARNING:tensorflow:From /home/sven/anaconda3/envs/dcmr/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 11:58:33,853 WARNING From /home/sven/anaconda3/envs/dcmr/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    }
   ],
   "source": [
    "from src.models.Models import create_RegistrationModel\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "if tensorflow.distribute.has_strategy():\n",
    "    strategy = tensorflow.distribute.get_strategy()\n",
    "else:\n",
    "    # distribute the training with the \"mirrored data\"-paradigm across multiple gpus if available, if not use gpu 0\n",
    "    strategy = tensorflow.distribute.MirroredStrategy(devices=config.get('GPUS', [\"/gpu:0\"]))\n",
    "with strategy.scope():\n",
    "    model = create_RegistrationModel(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simpleregister\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 5, 64, 128,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_unstack (TensorFlow [(None, 64, 128, 128 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "unet (Functional)               (None, 64, 128, 128, 1604832     tf_op_layer_unstack[0][3]        \n",
      "                                                                 tf_op_layer_unstack[0][1]        \n",
      "                                                                 tf_op_layer_unstack[0][2]        \n",
      "                                                                 tf_op_layer_unstack[0][4]        \n",
      "                                                                 tf_op_layer_unstack[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "unet2flow (Conv3D)              (None, 64, 128, 128, 1299        unet[0][0]                       \n",
      "                                                                 unet[1][0]                       \n",
      "                                                                 unet[2][0]                       \n",
      "                                                                 unet[3][0]                       \n",
      "                                                                 unet[4][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "deformable_layer (SpatialTransf (None, 64, 128, 128, 0           tf_op_layer_unstack[0][0]        \n",
      "                                                                 unet2flow[4][0]                  \n",
      "                                                                 tf_op_layer_unstack[0][1]        \n",
      "                                                                 unet2flow[1][0]                  \n",
      "                                                                 tf_op_layer_unstack[0][2]        \n",
      "                                                                 unet2flow[2][0]                  \n",
      "                                                                 tf_op_layer_unstack[0][3]        \n",
      "                                                                 unet2flow[0][0]                  \n",
      "                                                                 tf_op_layer_unstack[0][4]        \n",
      "                                                                 unet2flow[3][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5, 64, 128,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack (TensorFlowOp [(None, 5, 64, 128,  0           deformable_layer[0][0]           \n",
      "                                                                 deformable_layer[1][0]           \n",
      "                                                                 deformable_layer[2][0]           \n",
      "                                                                 deformable_layer[3][0]           \n",
      "                                                                 deformable_layer[4][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack_1 (TensorFlow [(None, 5, 64, 128,  0           unet2flow[4][0]                  \n",
      "                                                                 unet2flow[1][0]                  \n",
      "                                                                 unet2flow[2][0]                  \n",
      "                                                                 unet2flow[0][0]                  \n",
      "                                                                 unet2flow[3][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,606,131\n",
      "Trainable params: 1,606,131\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.losses import mse\n",
    "from src.utils.Metrics import Grad, MSE_\n",
    "if 'strategy' in locals():\n",
    "    pass\n",
    "else:\n",
    "    # distribute the training with the \"mirrored data\"-paradigm across multiple gpus if available, if not use gpu 0\n",
    "    strategy = tensorflow.distribute.MirroredStrategy(devices=config.get('GPUS', [\"/gpu:0\"]))\n",
    "with strategy.scope():\n",
    "\n",
    "    losses = [mse, Grad('l1').loss]\n",
    "    weights = [1,0.01]\n",
    "    model.compile(optimizer=tensorflow.keras.optimizers.Adam(), loss=losses, loss_weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From /home/sven/anaconda3/envs/dcmr/lib/python3.8/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 11:58:36,569 WARNING From /home/sven/anaconda3/envs/dcmr/lib/python3.8/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 36 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 11:58:43,746 INFO batch_all_reduce: 36 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 11:58:44,141 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 11:58:44,143 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 11:58:44,146 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 11:58:44,149 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 11:58:44,152 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 11:58:44,155 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 36 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 11:58:53,010 INFO batch_all_reduce: 36 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 11:58:53,227 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 11:58:53,229 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 11:58:53,232 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-21 11:58:53,234 INFO Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - ETA: 0s - loss: 0.1343 - tf_op_layer_stack_loss: 0.1324 - tf_op_layer_stack_1_loss: 0.1890\n",
      "Epoch 00001: loss improved from inf to 0.13433, saving model to exp/temp/windowmotion/2021-05-21_11_58/model/model.h5\n",
      "104/104 [==============================] - 224s 2s/step - loss: 0.1343 - tf_op_layer_stack_loss: 0.1324 - tf_op_layer_stack_1_loss: 0.1890 - val_loss: 0.1342 - val_tf_op_layer_stack_loss: 0.1341 - val_tf_op_layer_stack_1_loss: 0.0120 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1094 - tf_op_layer_stack_loss: 0.1090 - tf_op_layer_stack_1_loss: 0.0344\n",
      "Epoch 00002: loss improved from 0.13433 to 0.10937, saving model to exp/temp/windowmotion/2021-05-21_11_58/model/model.h5\n",
      "104/104 [==============================] - 233s 2s/step - loss: 0.1094 - tf_op_layer_stack_loss: 0.1090 - tf_op_layer_stack_1_loss: 0.0344 - val_loss: 0.1277 - val_tf_op_layer_stack_loss: 0.1275 - val_tf_op_layer_stack_1_loss: 0.0223 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1051 - tf_op_layer_stack_loss: 0.1046 - tf_op_layer_stack_1_loss: 0.0418\n",
      "Epoch 00003: loss improved from 0.10937 to 0.10506, saving model to exp/temp/windowmotion/2021-05-21_11_58/model/model.h5\n",
      "104/104 [==============================] - 233s 2s/step - loss: 0.1051 - tf_op_layer_stack_loss: 0.1046 - tf_op_layer_stack_1_loss: 0.0418 - val_loss: 0.1263 - val_tf_op_layer_stack_loss: 0.1260 - val_tf_op_layer_stack_1_loss: 0.0315 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1035 - tf_op_layer_stack_loss: 0.1031 - tf_op_layer_stack_1_loss: 0.0443\n",
      "Epoch 00004: loss improved from 0.10506 to 0.10351, saving model to exp/temp/windowmotion/2021-05-21_11_58/model/model.h5\n",
      "104/104 [==============================] - 234s 2s/step - loss: 0.1035 - tf_op_layer_stack_loss: 0.1031 - tf_op_layer_stack_1_loss: 0.0443 - val_loss: 0.1240 - val_tf_op_layer_stack_loss: 0.1237 - val_tf_op_layer_stack_1_loss: 0.0364 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1031 - tf_op_layer_stack_loss: 0.1027 - tf_op_layer_stack_1_loss: 0.0444\n",
      "Epoch 00005: loss improved from 0.10351 to 0.10315, saving model to exp/temp/windowmotion/2021-05-21_11_58/model/model.h5\n",
      "104/104 [==============================] - 238s 2s/step - loss: 0.1031 - tf_op_layer_stack_loss: 0.1027 - tf_op_layer_stack_1_loss: 0.0444 - val_loss: 0.1211 - val_tf_op_layer_stack_loss: 0.1208 - val_tf_op_layer_stack_1_loss: 0.0357 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1049 - tf_op_layer_stack_loss: 0.1044 - tf_op_layer_stack_1_loss: 0.0453\n",
      "Epoch 00006: loss did not improve from 0.10315\n",
      "104/104 [==============================] - 238s 2s/step - loss: 0.1049 - tf_op_layer_stack_loss: 0.1044 - tf_op_layer_stack_1_loss: 0.0453 - val_loss: 0.1203 - val_tf_op_layer_stack_loss: 0.1200 - val_tf_op_layer_stack_1_loss: 0.0290 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1054 - tf_op_layer_stack_loss: 0.1050 - tf_op_layer_stack_1_loss: 0.0460\n",
      "Epoch 00007: loss did not improve from 0.10315\n",
      "104/104 [==============================] - 236s 2s/step - loss: 0.1054 - tf_op_layer_stack_loss: 0.1050 - tf_op_layer_stack_1_loss: 0.0460 - val_loss: 0.1202 - val_tf_op_layer_stack_loss: 0.1199 - val_tf_op_layer_stack_1_loss: 0.0368 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1040 - tf_op_layer_stack_loss: 0.1035 - tf_op_layer_stack_1_loss: 0.0457\n",
      "Epoch 00008: loss did not improve from 0.10315\n",
      "104/104 [==============================] - 235s 2s/step - loss: 0.1040 - tf_op_layer_stack_loss: 0.1035 - tf_op_layer_stack_1_loss: 0.0457 - val_loss: 0.1206 - val_tf_op_layer_stack_loss: 0.1203 - val_tf_op_layer_stack_1_loss: 0.0336 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1036 - tf_op_layer_stack_loss: 0.1031 - tf_op_layer_stack_1_loss: 0.0473\n",
      "Epoch 00009: loss did not improve from 0.10315\n",
      "104/104 [==============================] - 235s 2s/step - loss: 0.1036 - tf_op_layer_stack_loss: 0.1031 - tf_op_layer_stack_1_loss: 0.0473 - val_loss: 0.1199 - val_tf_op_layer_stack_loss: 0.1196 - val_tf_op_layer_stack_1_loss: 0.0309 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1024 - tf_op_layer_stack_loss: 0.1019 - tf_op_layer_stack_1_loss: 0.0458\n",
      "Epoch 00010: loss improved from 0.10315 to 0.10238, saving model to exp/temp/windowmotion/2021-05-21_11_58/model/model.h5\n",
      "104/104 [==============================] - 234s 2s/step - loss: 0.1024 - tf_op_layer_stack_loss: 0.1019 - tf_op_layer_stack_1_loss: 0.0458 - val_loss: 0.1175 - val_tf_op_layer_stack_loss: 0.1172 - val_tf_op_layer_stack_1_loss: 0.0370 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1017 - tf_op_layer_stack_loss: 0.1012 - tf_op_layer_stack_1_loss: 0.0468\n",
      "Epoch 00011: loss improved from 0.10238 to 0.10167, saving model to exp/temp/windowmotion/2021-05-21_11_58/model/model.h5\n",
      "104/104 [==============================] - 234s 2s/step - loss: 0.1017 - tf_op_layer_stack_loss: 0.1012 - tf_op_layer_stack_1_loss: 0.0468 - val_loss: 0.1209 - val_tf_op_layer_stack_loss: 0.1205 - val_tf_op_layer_stack_1_loss: 0.0411 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1012 - tf_op_layer_stack_loss: 0.1008 - tf_op_layer_stack_1_loss: 0.0473\n",
      "Epoch 00012: loss improved from 0.10167 to 0.10123, saving model to exp/temp/windowmotion/2021-05-21_11_58/model/model.h5\n",
      "104/104 [==============================] - 236s 2s/step - loss: 0.1012 - tf_op_layer_stack_loss: 0.1008 - tf_op_layer_stack_1_loss: 0.0473 - val_loss: 0.1198 - val_tf_op_layer_stack_loss: 0.1194 - val_tf_op_layer_stack_1_loss: 0.0363 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1015 - tf_op_layer_stack_loss: 0.1010 - tf_op_layer_stack_1_loss: 0.0466\n",
      "Epoch 00013: loss did not improve from 0.10123\n",
      "104/104 [==============================] - 236s 2s/step - loss: 0.1015 - tf_op_layer_stack_loss: 0.1010 - tf_op_layer_stack_1_loss: 0.0466 - val_loss: 0.1223 - val_tf_op_layer_stack_loss: 0.1219 - val_tf_op_layer_stack_1_loss: 0.0386 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1020 - tf_op_layer_stack_loss: 0.1015 - tf_op_layer_stack_1_loss: 0.0473\n",
      "Epoch 00014: loss did not improve from 0.10123\n",
      "104/104 [==============================] - 238s 2s/step - loss: 0.1020 - tf_op_layer_stack_loss: 0.1015 - tf_op_layer_stack_1_loss: 0.0473 - val_loss: 0.1270 - val_tf_op_layer_stack_loss: 0.1267 - val_tf_op_layer_stack_1_loss: 0.0326 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1038 - tf_op_layer_stack_loss: 0.1034 - tf_op_layer_stack_1_loss: 0.0473\n",
      "Epoch 00015: loss did not improve from 0.10123\n",
      "104/104 [==============================] - 235s 2s/step - loss: 0.1038 - tf_op_layer_stack_loss: 0.1034 - tf_op_layer_stack_1_loss: 0.0473 - val_loss: 0.1195 - val_tf_op_layer_stack_loss: 0.1192 - val_tf_op_layer_stack_1_loss: 0.0356 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1061 - tf_op_layer_stack_loss: 0.1056 - tf_op_layer_stack_1_loss: 0.0475\n",
      "Epoch 00016: loss did not improve from 0.10123\n",
      "104/104 [==============================] - 238s 2s/step - loss: 0.1061 - tf_op_layer_stack_loss: 0.1056 - tf_op_layer_stack_1_loss: 0.0475 - val_loss: 0.1201 - val_tf_op_layer_stack_loss: 0.1198 - val_tf_op_layer_stack_1_loss: 0.0371 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1073 - tf_op_layer_stack_loss: 0.1068 - tf_op_layer_stack_1_loss: 0.0479\n",
      "Epoch 00017: loss did not improve from 0.10123\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "104/104 [==============================] - 236s 2s/step - loss: 0.1073 - tf_op_layer_stack_loss: 0.1068 - tf_op_layer_stack_1_loss: 0.0479 - val_loss: 0.1252 - val_tf_op_layer_stack_loss: 0.1248 - val_tf_op_layer_stack_1_loss: 0.0343 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1028 - tf_op_layer_stack_loss: 0.1023 - tf_op_layer_stack_1_loss: 0.0480\n",
      "Epoch 00018: loss did not improve from 0.10123\n",
      "104/104 [==============================] - 235s 2s/step - loss: 0.1028 - tf_op_layer_stack_loss: 0.1023 - tf_op_layer_stack_1_loss: 0.0480 - val_loss: 0.1206 - val_tf_op_layer_stack_loss: 0.1202 - val_tf_op_layer_stack_1_loss: 0.0362 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0999 - tf_op_layer_stack_loss: 0.0995 - tf_op_layer_stack_1_loss: 0.0465\n",
      "Epoch 00019: loss improved from 0.10123 to 0.09993, saving model to exp/temp/windowmotion/2021-05-21_11_58/model/model.h5\n",
      "104/104 [==============================] - 237s 2s/step - loss: 0.0999 - tf_op_layer_stack_loss: 0.0995 - tf_op_layer_stack_1_loss: 0.0465 - val_loss: 0.1159 - val_tf_op_layer_stack_loss: 0.1154 - val_tf_op_layer_stack_1_loss: 0.0442 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1011 - tf_op_layer_stack_loss: 0.1006 - tf_op_layer_stack_1_loss: 0.0470\n",
      "Epoch 00020: loss did not improve from 0.09993\n",
      "104/104 [==============================] - 236s 2s/step - loss: 0.1011 - tf_op_layer_stack_loss: 0.1006 - tf_op_layer_stack_1_loss: 0.0470 - val_loss: 0.1209 - val_tf_op_layer_stack_loss: 0.1205 - val_tf_op_layer_stack_1_loss: 0.0355 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1010 - tf_op_layer_stack_loss: 0.1006 - tf_op_layer_stack_1_loss: 0.0472\n",
      "Epoch 00021: loss did not improve from 0.09993\n",
      "104/104 [==============================] - 236s 2s/step - loss: 0.1010 - tf_op_layer_stack_loss: 0.1006 - tf_op_layer_stack_1_loss: 0.0472 - val_loss: 0.1197 - val_tf_op_layer_stack_loss: 0.1194 - val_tf_op_layer_stack_1_loss: 0.0347 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1000 - tf_op_layer_stack_loss: 0.0995 - tf_op_layer_stack_1_loss: 0.0471\n",
      "Epoch 00022: loss did not improve from 0.09993\n",
      "104/104 [==============================] - 235s 2s/step - loss: 0.1000 - tf_op_layer_stack_loss: 0.0995 - tf_op_layer_stack_1_loss: 0.0471 - val_loss: 0.1136 - val_tf_op_layer_stack_loss: 0.1133 - val_tf_op_layer_stack_1_loss: 0.0367 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1003 - tf_op_layer_stack_loss: 0.0999 - tf_op_layer_stack_1_loss: 0.0470\n",
      "Epoch 00023: loss did not improve from 0.09993\n",
      "104/104 [==============================] - 235s 2s/step - loss: 0.1003 - tf_op_layer_stack_loss: 0.0999 - tf_op_layer_stack_1_loss: 0.0470 - val_loss: 0.1171 - val_tf_op_layer_stack_loss: 0.1167 - val_tf_op_layer_stack_1_loss: 0.0376 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1022 - tf_op_layer_stack_loss: 0.1017 - tf_op_layer_stack_1_loss: 0.0470\n",
      "Epoch 00024: loss did not improve from 0.09993\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "104/104 [==============================] - 240s 2s/step - loss: 0.1022 - tf_op_layer_stack_loss: 0.1017 - tf_op_layer_stack_1_loss: 0.0470 - val_loss: 0.1220 - val_tf_op_layer_stack_loss: 0.1217 - val_tf_op_layer_stack_1_loss: 0.0312 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1031 - tf_op_layer_stack_loss: 0.1026 - tf_op_layer_stack_1_loss: 0.0475\n",
      "Epoch 00025: loss did not improve from 0.09993\n",
      "104/104 [==============================] - 236s 2s/step - loss: 0.1031 - tf_op_layer_stack_loss: 0.1026 - tf_op_layer_stack_1_loss: 0.0475 - val_loss: 0.1138 - val_tf_op_layer_stack_loss: 0.1134 - val_tf_op_layer_stack_1_loss: 0.0384 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0999 - tf_op_layer_stack_loss: 0.0994 - tf_op_layer_stack_1_loss: 0.0473\n",
      "Epoch 00026: loss improved from 0.09993 to 0.09985, saving model to exp/temp/windowmotion/2021-05-21_11_58/model/model.h5\n",
      "104/104 [==============================] - 236s 2s/step - loss: 0.0999 - tf_op_layer_stack_loss: 0.0994 - tf_op_layer_stack_1_loss: 0.0473 - val_loss: 0.1134 - val_tf_op_layer_stack_loss: 0.1129 - val_tf_op_layer_stack_1_loss: 0.0411 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1010 - tf_op_layer_stack_loss: 0.1006 - tf_op_layer_stack_1_loss: 0.0475\n",
      "Epoch 00027: loss did not improve from 0.09985\n",
      "104/104 [==============================] - 237s 2s/step - loss: 0.1010 - tf_op_layer_stack_loss: 0.1006 - tf_op_layer_stack_1_loss: 0.0475 - val_loss: 0.1191 - val_tf_op_layer_stack_loss: 0.1187 - val_tf_op_layer_stack_1_loss: 0.0350 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1005 - tf_op_layer_stack_loss: 0.1000 - tf_op_layer_stack_1_loss: 0.0469\n",
      "Epoch 00028: loss did not improve from 0.09985\n",
      "104/104 [==============================] - 236s 2s/step - loss: 0.1005 - tf_op_layer_stack_loss: 0.1000 - tf_op_layer_stack_1_loss: 0.0469 - val_loss: 0.1147 - val_tf_op_layer_stack_loss: 0.1144 - val_tf_op_layer_stack_1_loss: 0.0380 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1016 - tf_op_layer_stack_loss: 0.1011 - tf_op_layer_stack_1_loss: 0.0471\n",
      "Epoch 00029: loss did not improve from 0.09985\n",
      "104/104 [==============================] - 236s 2s/step - loss: 0.1016 - tf_op_layer_stack_loss: 0.1011 - tf_op_layer_stack_1_loss: 0.0471 - val_loss: 0.1201 - val_tf_op_layer_stack_loss: 0.1197 - val_tf_op_layer_stack_1_loss: 0.0354 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1008 - tf_op_layer_stack_loss: 0.1003 - tf_op_layer_stack_1_loss: 0.0475\n",
      "Epoch 00030: loss did not improve from 0.09985\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "104/104 [==============================] - 239s 2s/step - loss: 0.1008 - tf_op_layer_stack_loss: 0.1003 - tf_op_layer_stack_1_loss: 0.0475 - val_loss: 0.1149 - val_tf_op_layer_stack_loss: 0.1145 - val_tf_op_layer_stack_1_loss: 0.0395 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1006 - tf_op_layer_stack_loss: 0.1001 - tf_op_layer_stack_1_loss: 0.0474\n",
      "Epoch 00031: loss did not improve from 0.09985\n",
      "104/104 [==============================] - 242s 2s/step - loss: 0.1006 - tf_op_layer_stack_loss: 0.1001 - tf_op_layer_stack_1_loss: 0.0474 - val_loss: 0.1176 - val_tf_op_layer_stack_loss: 0.1172 - val_tf_op_layer_stack_1_loss: 0.0393 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      " 50/104 [=============>................] - ETA: 1:40 - loss: 0.0978 - tf_op_layer_stack_loss: 0.0974 - tf_op_layer_stack_1_loss: 0.0466"
     ]
    }
   ],
   "source": [
    "from src.utils.KerasCallbacks import get_callbacks\n",
    "\n",
    "results = model.fit(\n",
    "    x=batch_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=100,\n",
    "    callbacks = get_callbacks(config, batch_generator,validation_generator),\n",
    "    initial_epoch=0,\n",
    "\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5, 64, 128, 128, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5, 64, 128, 128, 1)\n",
      "(2, 5, 64, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "transformed, flow = pred\n",
    "print(transformed.shape)\n",
    "print(flow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('reports/flow.npz',flow)\n",
    "np.save('reports/input.npz',inputs)\n",
    "np.save('reports/target.npz',outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save one 3D volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = 'reports/exampleflows'\n",
    "experiment_ = '{}/fullimage128_32'.format(export_path)\n",
    "ensure_dir(experiment_)\n",
    "flowname = os.path.join(experiment_, '_flow.nii')\n",
    "firstfilename = os.path.join(experiment_, '_cmr.nii')\n",
    "secondfilename = os.path.join(experiment_, '_targetcmr.nii')\n",
    "t = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-04 18:32:00,417 INFO reports/exampleflows/full_64_128_128\n"
     ]
    }
   ],
   "source": [
    "def save_3d(nda, fname):\n",
    "    # save one flowfield\n",
    "    sitk_img = sitk.GetImageFromArray(nda, isVector=False)\n",
    "    sitk.WriteImage(sitk_img, fname)\n",
    "\n",
    "def save_all_3d_vols(inputs, outputs, flow, export_path='reports/exampleflows', exp='fullimage128_32_temp'):\n",
    "    experiment_ = '{}/{}'.format(export_path, exp)\n",
    "    info(experiment_)\n",
    "    ensure_dir(experiment_)\n",
    "    flowname = os.path.join(experiment_, '_flow.nii')\n",
    "    firstfilename = os.path.join(experiment_, '_cmr.nii')\n",
    "    secondfilename = os.path.join(experiment_, '_targetcmr.nii')\n",
    "    \n",
    "    # invert the axis\n",
    "    flow = np.einsum('tzyxc->cxyzt', flow)\n",
    "    inputs = np.einsum('tzyxc->cxyzt', inputs)\n",
    "    outputs = np.einsum('tzyxc->cxyzt', outputs)\n",
    "    \n",
    "    _ = [save_3d(flow[...,t], flowname.replace('.nii', '_{}_.nii'.format(t))) for t in range(flow.shape[-1])]\n",
    "    _ = [save_3d(inputs[...,t], firstfilename.replace('.nii', '_{}_.nii'.format(t))) for t in range(inputs.shape[-1])]\n",
    "    _ = [save_3d(outputs[...,t], secondfilename.replace('.nii', '_{}_.nii'.format(t))) for t in range(outputs.shape[-1])]\n",
    "    \n",
    "    _ = [save_3d(flow[...,t,:], flowname.replace('.nii', '_sequence_{}_.nii'.format(t))) for t in range(flow.shape[-2])]\n",
    "    _ = [save_3d(inputs[...,t,:], firstfilename.replace('.nii', '_sequence_{}_.nii'.format(t))) for t in range(inputs.shape[-2])]\n",
    "    _ = [save_3d(outputs[...,t,:], secondfilename.replace('.nii', '_sequence_{}_.nii'.format(t))) for t in range(outputs.shape[-2])]\n",
    "    \n",
    "save_all_3d_vols(inputs[0], outputs[0], flow[0], exp='full_64_128_128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32, 128, 128, 3)\n",
      "(32, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# save one flowfield\n",
    "flow_single = flow[0]\n",
    "print(flow_single.shape)\n",
    "flow_single = np.einsum('tzyxc->cxyzt', flow_single)\n",
    "flow_single = flow_single[...,t]\n",
    "flow_sitk = sitk.GetImageFromArray(flow_single, isVector=False)\n",
    "print(flow_sitk.GetSize())\n",
    "sitk.WriteImage(flow_sitk, flowname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32, 128, 128, 1)\n",
      "(32, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# save the first time step\n",
    "inputs_single = inputs[0]\n",
    "print(inputs_single.shape)\n",
    "inputs_single = np.einsum('tzyxc->cxyzt', inputs_single)\n",
    "inputs_single = inputs_single[...,t]\n",
    "input_sitk = sitk.GetImageFromArray(inputs_single, isVector=False)\n",
    "print(input_sitk.GetSize())\n",
    "sitk.WriteImage(input_sitk, firstfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32, 128, 128, 1)\n",
      "(32, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# save the second time step\n",
    "outputs_single = outputs[0]\n",
    "print(outputs_single.shape)\n",
    "outputs_single = np.einsum('tzyxc->cxyzt', outputs_single)\n",
    "outputs_single = outputs_single[...,t]\n",
    "output_sitk = sitk.GetImageFromArray(outputs_single, isVector=False)\n",
    "print(output_sitk.GetSize())\n",
    "sitk.WriteImage(output_sitk, secondfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save one 2D+T volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporalflowname = flowname.replace('flow.nii', 'tempflow.nii')\n",
    "temporalfirstfilename = firstfilename.replace('cmr.nii', 'tempcmr.nii')\n",
    "temporalsecondfilename = secondfilename.replace('targetcmr.nii', 'temptargetcmr.nii')\n",
    "slice_ = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32, 128, 128, 3)\n",
      "(3, 128, 128, 32, 5)\n",
      "(3, 128, 128, 5)\n",
      "(5, 128, 128, 3)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# save one 2D+t flowfield\n",
    "flow_single = flow[0]\n",
    "print(flow_single.shape)\n",
    "flow_single = np.einsum('tzyxc->cxyzt', flow_single)\n",
    "print(flow_single.shape)\n",
    "flow_single = flow_single[:,:,:,slice_,:]\n",
    "print(flow_single.shape)\n",
    "flow_sitk = sitk.GetImageFromArray(flow_single, isVector=False)\n",
    "print(flow_sitk.GetSize())\n",
    "print(flow_sitk.GetNumberOfComponentsPerPixel())\n",
    "sitk.WriteImage(flow_sitk, temporalflowname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32, 128, 128, 1)\n",
      "(1, 128, 128, 32, 5)\n",
      "(1, 128, 128, 5)\n",
      "(5, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# save the first time step\n",
    "inputs_single = inputs[0]\n",
    "print(inputs_single.shape)\n",
    "inputs_single = np.einsum('tzyxc->cxyzt', inputs_single)\n",
    "print(inputs_single.shape)\n",
    "inputs_single = inputs_single[:,:,:,slice_,:]\n",
    "print(inputs_single.shape)\n",
    "input_sitk = sitk.GetImageFromArray(inputs_single, isVector=False)\n",
    "print(input_sitk.GetSize())\n",
    "sitk.WriteImage(input_sitk, temporalfirstfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32, 128, 128, 1)\n",
      "(1, 128, 128, 32, 5)\n",
      "(1, 128, 128, 5)\n",
      "(5, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# save the 2nd time step\n",
    "outputs_single = outputs[0]\n",
    "print(outputs_single.shape)\n",
    "outputs_single = np.einsum('tzyxc->cxyzt', outputs_single)\n",
    "print(outputs_single.shape)\n",
    "outputs_single = outputs_single[:,:,:,slice_,:]\n",
    "print(outputs_single.shape)\n",
    "output_sitk = sitk.GetImageFromArray(outputs_single, isVector=False)\n",
    "print(output_sitk.GetSize())\n",
    "sitk.WriteImage(output_sitk, temporalsecondfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save 4D flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 30, 128, 128, 3)\n",
      "(3, 128, 128, 30, 5)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# save the second time step\n",
    "temp = flow[0]\n",
    "print(temp.shape)\n",
    "#temp = np.einsum('tzyxc->ctzyx', temp)\n",
    "#temp = [temp[:,:,:,i,:] for i in range(outputs_single.shape[-2])]\n",
    "temp = sitk.JoinSeries([sitk.GetImageFromArray(img, isVector=False) for img in temp])\n",
    "print(temp.GetSize())\n",
    "print(temp.GetNumberOfComponentsPerPixel())\n",
    "sitk.WriteImage(temp, os.path.join(experiment_, '4dflow.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 30, 128, 128, 3)\n",
      "(5, 128, 128, 3)\n",
      "(3, 128, 128, 5)\n",
      "(3, 128, 128, 10)\n",
      "(128, 128, 3)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# stack two slices - tests\n",
    "flow_single = flow[0]\n",
    "print(flow_single.shape)\n",
    "flow_single = flow_single[:,slice_,:,:,:]\n",
    "print(flow_single.shape)\n",
    "flow_single = np.einsum('tyxc->cxyt', flow_single)\n",
    "print(flow_single.shape)\n",
    "flow_single = np.concatenate([flow_single,flow_single], axis=-1)\n",
    "print(flow_single.shape)\n",
    "flow_sitk = sitk.GetImageFromArray(flow_single, isVector=True)\n",
    "print(flow_sitk.GetSize())\n",
    "print(flow_sitk.GetNumberOfComponentsPerPixel())\n",
    "sitk.WriteImage(flow_sitk, temporalflowname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 30, 128, 128, 3)\n",
      "(5, 1, 128, 128, 3)\n",
      "(3, 128, 128, 5)\n",
      "(3, 128, 128, 150)\n",
      "(150, 128, 128, 3)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# stack z x 2D+T flows - works\n",
    "flow_single = flow[0]\n",
    "print(flow_single.shape)\n",
    "flows = np.split(flow_single,indices_or_sections=flow_single.shape[1], axis=1)\n",
    "print(flows[0].shape)\n",
    "flows = [np.einsum('tyxc->cxyt', np.squeeze(f)) for f in flows]\n",
    "print(flows[0].shape)\n",
    "flows = np.concatenate(flows, axis=-1)\n",
    "print(flows.shape)\n",
    "flow_sitk = sitk.GetImageFromArray(flows, isVector=False)\n",
    "print(flow_sitk.GetSize())\n",
    "print(flow_sitk.GetNumberOfComponentsPerPixel())\n",
    "sitk.WriteImage(flow_sitk, experiment_+'/stacked_2d+t.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 30, 128, 128)\n",
      "(128, 128, 150)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# stack z x 2D+T slices - tests\n",
    "flow_single = np.squeeze(inputs[0])\n",
    "print(flow_single.shape)\n",
    "flow_single = np.reshape(flow_single,(150,128,128))\n",
    "flow_sitk = sitk.GetImageFromArray(flow_single, isVector=False)\n",
    "print(flow_sitk.GetSize())\n",
    "print(flow_sitk.GetNumberOfComponentsPerPixel())\n",
    "sitk.WriteImage(flow_sitk, experiment_+'/stacked_1st_cmr.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Wrong number or type of arguments for overloaded function 'new_DisplacementFieldTransform'.\n  Possible C/C++ prototypes are:\n    itk::simple::DisplacementFieldTransform::DisplacementFieldTransform(unsigned int)\n    itk::simple::DisplacementFieldTransform::DisplacementFieldTransform(itk::simple::Image &)\n    itk::simple::DisplacementFieldTransform::DisplacementFieldTransform(itk::simple::DisplacementFieldTransform const &)\n    itk::simple::DisplacementFieldTransform::DisplacementFieldTransform(itk::simple::Transform const &)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-73b37a9acd07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mflow_single\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tzyxc->cxyzt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow_single\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mflows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_or_sections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mflows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisplacementFieldTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mflow_sitk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJoinSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow_sitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-73b37a9acd07>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mflow_single\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tzyxc->cxyzt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow_single\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mflows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_or_sections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mflows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisplacementFieldTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mflow_sitk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJoinSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow_sitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcmr/lib/python3.8/site-packages/SimpleITK/SimpleITK.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   4433\u001b[0m         \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDisplacementFieldTransform\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransform\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDisplacementFieldTransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4434\u001b[0m         \"\"\"\n\u001b[0;32m-> 4435\u001b[0;31m         \u001b[0m_SimpleITK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisplacementFieldTransform_swiginit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SimpleITK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_DisplacementFieldTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4437\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mGetName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Wrong number or type of arguments for overloaded function 'new_DisplacementFieldTransform'.\n  Possible C/C++ prototypes are:\n    itk::simple::DisplacementFieldTransform::DisplacementFieldTransform(unsigned int)\n    itk::simple::DisplacementFieldTransform::DisplacementFieldTransform(itk::simple::Image &)\n    itk::simple::DisplacementFieldTransform::DisplacementFieldTransform(itk::simple::DisplacementFieldTransform const &)\n    itk::simple::DisplacementFieldTransform::DisplacementFieldTransform(itk::simple::Transform const &)\n"
     ]
    }
   ],
   "source": [
    "# save one 2D+t flowfield\n",
    "flow_single = flow[0]\n",
    "flow_single = np.einsum('tzyxc->cxyzt', flow_single)\n",
    "flows = np.split(flow_single, indices_or_sections=5, axis=-1)\n",
    "flows = [sitk.DisplacementFieldTransform(f) for f in flows]\n",
    "flow_sitk = sitk.JoinSeries(flows)\n",
    "print(flow_sitk.GetSize())\n",
    "sitk.WriteTransform(flow_sitk, 'reports/examplefullflow_4d.nrrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 30, 128, 128, 3)\n",
      "(5, 30, 128, 128, 3)\n",
      "(5, 30, 128, 128, 3)\n",
      "(3, 128, 128, 30, 5)\n"
     ]
    }
   ],
   "source": [
    "# save one flowfield\n",
    "flow_single = flow[0]\n",
    "print(flow_single.shape)\n",
    "#flow_single = np.einsum('tzyxc->ctzyx', flow_single)\n",
    "print(flow_single.shape)\n",
    "#flow_single = flow_single[...,t]\n",
    "\n",
    "#flow_single = np.reshape(flow_single, newshape=(15,30,128,128), order='F')\n",
    "print(flow_single.shape)\n",
    "flow_sitk = sitk.GetImageFromArray(flow_single, isVector=False)\n",
    "print(flow_sitk.GetSize())\n",
    "sitk.WriteImage(flow_sitk, flowname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_sitk = sitk.GetImageFromArray(flow[0], isVector=False)\n",
    "sitk.WriteImage(flow_sitk, 'reports/example2flow.ni.gz')\n",
    "\n",
    "\"\"\"inputs_sitk = sitk.GetImageFromArray(inputs)\n",
    "outputs_sitk = sitk.GetImageFromArray(outputs)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2, description='t', max=5), IntSlider(value=2, description='slice_z', ma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.visualization.Visualize import create_quiver_plot\n",
    "\n",
    "@interact\n",
    "def show_pred(t=(0,5), slice_z=(0,5), debug_=False):\n",
    "    info('input')\n",
    "    if debug_:list(map(lambda x: show_2D_or_3D(img=x[::slice_z], interpol='bilinear',dpi=100,f_size=(5,5)), inputs[0][t:t+1]));plt.show()\n",
    "    info('target')\n",
    "    if debug_:list(map(lambda x: show_2D_or_3D(img=x[::slice_z], interpol='bilinear',dpi=100,f_size=(5,5)), outputs[0][t:t+1]));plt.show()\n",
    "    diff = inputs - outputs\n",
    "    info('diff input')\n",
    "    if debug_:list(map(lambda x: show_2D_or_3D(img=x[::slice_z], interpol='bilinear',dpi=100,f_size=(5,5)), diff[0][t:t+1]));plt.show()\n",
    "    info('pred')\n",
    "    if debug_:list(map(lambda x: show_2D_or_3D(img=x[::slice_z], interpol='bilinear',dpi=100,f_size=(5,5)), transformed[0][t:t+1]));plt.show()\n",
    "    info('diff pred')\n",
    "    diff = transformed - outputs\n",
    "    if debug_:list(map(lambda x: show_2D_or_3D(img=x[::slice_z], interpol='bilinear',dpi=100,f_size=(5,5)), diff[0][t:t+1]));plt.show()\n",
    "    if debug_:fig,axes = plt.subplots(1,flow.shape[2]//slice_z, figsize=(24,2))\n",
    "    if debug_:list(map(lambda x: create_quiver_plot(flowfield_2d=x[1],indexing='ij', scale=0.5, N=1,ax=x[0]), zip(axes,flow[0][t][::slice_z]))); plt.show() # third timestep\n",
    "    list(map(lambda x: show_2D_or_3D(mask=x[::slice_z], interpol='bilinear',dpi=100,f_size=(5,5)) and plt.show(), flow[0][t:t+1]))\n",
    "    plt.show()\n",
    "    if debug_:plt.hist(flow[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcmr",
   "language": "python",
   "name": "dcmr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03975527669449d8821665f2461868e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "06ca167e81f5435487738b6934bba1b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0ec7fa5b48f04926855c8fc908c1f041": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "description": "im",
       "layout": "IPY_MODEL_ffb395257ccf421eac21a146189c522e",
       "max": 1,
       "style": "IPY_MODEL_2c8d891a35d245dcbcab8bda643d604e"
      }
     },
     "0f23e170268c409494ee29f92691955f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1fdaccd2c7a74fbb884af9978443cc8a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "217385358494462a9305cc3b28bebba8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "TextModel",
      "state": {
       "description": "filename",
       "layout": "IPY_MODEL_ddffd4af61b348e0bfe51d75c8f85c20",
       "style": "IPY_MODEL_8ab14e86538b4465b99796933bfe75fa",
       "value": "temp_x.npy"
      }
     },
     "23aedf6c75ca40c7b8f4c2a3185d2aa3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "description": "batch",
       "layout": "IPY_MODEL_d478490f7a364c18807174383eed9190",
       "max": 104,
       "style": "IPY_MODEL_d96fd673360f441f9b0c1af9489bc214",
       "value": 52
      }
     },
     "2550a333b41d483dbf4b1d0db8d89967": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_477b48b8da2243e0ad79179749951e31"
      }
     },
     "2616a0595f934e2fab477f0180b95714": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "description": "slice_n",
       "layout": "IPY_MODEL_0f23e170268c409494ee29f92691955f",
       "max": 11,
       "min": 1,
       "style": "IPY_MODEL_a277e561a13547ac9cd2fbe444b7b4c4",
       "value": 6
      }
     },
     "2c8d891a35d245dcbcab8bda643d604e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "333bb6126e3c469fb1745e8b92fef007": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "CheckboxModel",
      "state": {
       "description": "save",
       "disabled": false,
       "layout": "IPY_MODEL_60d18aaaaad14ad8b765c72836dcdbf6",
       "style": "IPY_MODEL_5bcb16c65d5944528a5dfa1d3fdff462",
       "value": false
      }
     },
     "3c04a327b68241a1b2d10b103b739eed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3fbb5c815dad46fa9cd566913910d359": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "477b48b8da2243e0ad79179749951e31": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4a54e1ec3b1249429d62181364522026": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4a76f1242b43452e893af6a9769b7677": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "description": "batch",
       "layout": "IPY_MODEL_9354b8de2b164abd95f65d5ec1bfd64d",
       "max": 104,
       "style": "IPY_MODEL_aabb6b611e09483bada04e6bc8f1436f",
       "value": 52
      }
     },
     "5a1a309849e44b82885cf65ec18808de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5bcb16c65d5944528a5dfa1d3fdff462": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "60d18aaaaad14ad8b765c72836dcdbf6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "61a5be108d744301a2285dec0bf979da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "66edbc30022e4ad2aa681664f6f2128a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6946de78caca4ab1af604b46e2dcc46d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6f18b379e1f7445fa15f7f2af6e90d00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "description": "slice_n",
       "layout": "IPY_MODEL_06ca167e81f5435487738b6934bba1b1",
       "max": 11,
       "min": 1,
       "style": "IPY_MODEL_bf541029b1b94b36ae889413d4fbb229",
       "value": 6
      }
     },
     "6f22a59e350d4dc98421b7ed456d4a88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [
        "widget-interact"
       ],
       "children": [
        "IPY_MODEL_23aedf6c75ca40c7b8f4c2a3185d2aa3",
        "IPY_MODEL_f02d4585468e4376b6d193724d319492",
        "IPY_MODEL_6f18b379e1f7445fa15f7f2af6e90d00",
        "IPY_MODEL_89a341687a6f450b9ce7a20b41ea6301",
        "IPY_MODEL_cdd2b5ccd39e4339a2e7bbfa70aed4bf",
        "IPY_MODEL_9a7abdac922e45ada6915b4c1e4125a7",
        "IPY_MODEL_844f7e216fcf4b86aafbfbc7e5f4084b",
        "IPY_MODEL_e3046875fc4243d2abf3c7680dec7fdb"
       ],
       "layout": "IPY_MODEL_3fbb5c815dad46fa9cd566913910d359"
      }
     },
     "844f7e216fcf4b86aafbfbc7e5f4084b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Run Interact",
       "layout": "IPY_MODEL_d4a5e0d5a06443009a417287331c6886",
       "style": "IPY_MODEL_e5437d0b437042b89a210549f28e4ec5"
      }
     },
     "89a341687a6f450b9ce7a20b41ea6301": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "CheckboxModel",
      "state": {
       "description": "save",
       "disabled": false,
       "layout": "IPY_MODEL_d76abc76372a4c689e54be59f4a6d925",
       "style": "IPY_MODEL_5a1a309849e44b82885cf65ec18808de",
       "value": false
      }
     },
     "8a127887de6b43afab3debac74335aeb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "8ab14e86538b4465b99796933bfe75fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "925292ca9df04625ad177acc5fe6ab36": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9354b8de2b164abd95f65d5ec1bfd64d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9a7abdac922e45ada6915b4c1e4125a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "TextModel",
      "state": {
       "description": "filename",
       "layout": "IPY_MODEL_bb556084802b4774a02701dd7cc67c65",
       "style": "IPY_MODEL_03975527669449d8821665f2461868e8",
       "value": "temp_x.npy"
      }
     },
     "a0bd366b1775475987450eaa09e86b8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "TextModel",
      "state": {
       "description": "filepath",
       "layout": "IPY_MODEL_61a5be108d744301a2285dec0bf979da",
       "style": "IPY_MODEL_e8b44f7165b04bb18a09fc8c0498cda6",
       "value": "data/temp/"
      }
     },
     "a277e561a13547ac9cd2fbe444b7b4c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "aabb6b611e09483bada04e6bc8f1436f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b58573ccdb1e4fec9bb63d66a46bda72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Run Interact",
       "layout": "IPY_MODEL_1fdaccd2c7a74fbb884af9978443cc8a",
       "style": "IPY_MODEL_8a127887de6b43afab3debac74335aeb"
      }
     },
     "bb556084802b4774a02701dd7cc67c65": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bf541029b1b94b36ae889413d4fbb229": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c7354dfe0a9349d9b9451812e23116e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [
        "widget-interact"
       ],
       "children": [
        "IPY_MODEL_4a76f1242b43452e893af6a9769b7677",
        "IPY_MODEL_0ec7fa5b48f04926855c8fc908c1f041",
        "IPY_MODEL_2616a0595f934e2fab477f0180b95714",
        "IPY_MODEL_333bb6126e3c469fb1745e8b92fef007",
        "IPY_MODEL_a0bd366b1775475987450eaa09e86b8b",
        "IPY_MODEL_217385358494462a9305cc3b28bebba8",
        "IPY_MODEL_b58573ccdb1e4fec9bb63d66a46bda72",
        "IPY_MODEL_2550a333b41d483dbf4b1d0db8d89967"
       ],
       "layout": "IPY_MODEL_d02a0c1e930340be907eb5ce788504bd"
      }
     },
     "cdd2b5ccd39e4339a2e7bbfa70aed4bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "TextModel",
      "state": {
       "description": "filepath",
       "layout": "IPY_MODEL_925292ca9df04625ad177acc5fe6ab36",
       "style": "IPY_MODEL_3c04a327b68241a1b2d10b103b739eed",
       "value": "data/temp/"
      }
     },
     "d02a0c1e930340be907eb5ce788504bd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d478490f7a364c18807174383eed9190": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d4a5e0d5a06443009a417287331c6886": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d76abc76372a4c689e54be59f4a6d925": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d96fd673360f441f9b0c1af9489bc214": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ddffd4af61b348e0bfe51d75c8f85c20": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e3046875fc4243d2abf3c7680dec7fdb": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_66edbc30022e4ad2aa681664f6f2128a"
      }
     },
     "e5437d0b437042b89a210549f28e4ec5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "e8b44f7165b04bb18a09fc8c0498cda6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f02d4585468e4376b6d193724d319492": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "description": "im",
       "layout": "IPY_MODEL_6946de78caca4ab1af604b46e2dcc46d",
       "max": 1,
       "style": "IPY_MODEL_4a54e1ec3b1249429d62181364522026"
      }
     },
     "ffb395257ccf421eac21a146189c522e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
