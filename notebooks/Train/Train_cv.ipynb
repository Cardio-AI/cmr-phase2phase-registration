{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search for root_dir and set working directory\n",
      "Working directory set to: /mnt/ssd/git/dynamic-cmr-models\n",
      "['/gpu:0', '/gpu:1']\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------define logging and working directory\n",
    "from ProjectRoot import change_wd_to_project_root\n",
    "change_wd_to_project_root()\n",
    "from src.utils.Tensorflow_helper import choose_gpu_by_id\n",
    "# ------------------------------------------define GPU id/s to use, if given\n",
    "GPU_IDS = '0,1'\n",
    "GPUS = choose_gpu_by_id(GPU_IDS)\n",
    "print(GPUS)\n",
    "# ------------------------------------------jupyter magic config\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# ------------------------------------------ import helpers\n",
    "# this should import glob, os, and many other standard libs\n",
    "# local imports\n",
    "from src.utils.Notebook_imports import *\n",
    "from src.utils.Utils_io import Console_and_file_logger, init_config\n",
    "\n",
    "# import external libs\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "EXPERIMENT = 'cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8'\n",
    "#EXPERIMENT = 'baseline_label_transpose_smooth05/36_5_BiLSTM32_NoBn_conv5_size1_CCE_NOphaseaug_NOaug_b8'\n",
    "# EXPERIMENT = 'mased_scores/36_5_BiLSTM32_NoBn_conv5_size1_CCE_NOphaseaug_shift_rotate_reflectbordersgridaug'\n",
    "timestemp = str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M\")) # ad a timestep to each project to make repeated experiments unique\n",
    "\n",
    "EXPERIMENTS_ROOT = 'exp/'\n",
    "EXP_PATH = os.path.join(EXPERIMENTS_ROOT, EXPERIMENT, timestemp)\n",
    "MODEL_PATH = os.path.join(EXP_PATH, 'model', )\n",
    "TENSORBOARD_PATH = os.path.join(EXP_PATH, 'tensorboard_logs')\n",
    "CONFIG_PATH = os.path.join(EXP_PATH,'config')\n",
    "HISTORY_PATH = os.path.join(EXP_PATH, 'history')\n",
    "ensure_dir(MODEL_PATH)\n",
    "ensure_dir(TENSORBOARD_PATH)\n",
    "ensure_dir(CONFIG_PATH)\n",
    "ensure_dir(HISTORY_PATH)\n",
    "\n",
    "# define the input data paths and fold \n",
    "# first to the 4D Nrrd files, \n",
    "# second to a dataframe with a mapping of the Fold-number\n",
    "# Finally the path to the metadata\n",
    "DATA_PATH_SAX = '/mnt/ssd/data/gcn/02_imported_4D_unfiltered/SAX/'\n",
    "DF_FOLDS = '/mnt/ssd/data/gcn/02_imported_4D_unfiltered/df_kfold.csv'\n",
    "DF_META = '/mnt/ssd/data/gcn/02_imported_4D_unfiltered/SAx_3D_dicomTags_phase'\n",
    "FOLD = 0\n",
    "\n",
    "# General params\n",
    "SEED = 42 # define a seed for the generator shuffle\n",
    "BATCHSIZE = 8 # 32, 64, 24, 16, 1 for 3D use: 4\n",
    "GENERATOR_WORKER = BATCHSIZE # if not set, use batchsize\n",
    "EPOCHS = 100\n",
    "\n",
    "DIM = [8, 64, 64] # network input shape for spacing of 3, (z,y,x)\n",
    "T_SHAPE = 36\n",
    "SPACING = [8, 3, 3] # if resample, resample to this spacing, (z,y,x)\n",
    "\n",
    "# Model params\n",
    "DEPTH = 4 # depth of the encoder\n",
    "FILTERS = 32 # initial number of filters, will be doubled after each downsampling block\n",
    "M_POOL = [1, 2, 2]# size of max-pooling used for downsampling and upsampling\n",
    "F_SIZE = [3, 3, 3] # conv filter size\n",
    "BN_FIRST = False # decide if batch normalisation between conv and activation or afterwards\n",
    "BATCH_NORMALISATION = True # apply BN or not\n",
    "PAD = 'same' # padding strategy of the conv layers\n",
    "KERNEL_INIT = 'he_normal' # conv weight initialisation\n",
    "OPTIMIZER = 'adam' # Adam, Adagrad, RMSprop, Adadelta,  # https://keras.io/optimizers/\n",
    "ACTIVATION = 'relu' # tf.keras.layers.LeakyReLU(), relu or any other non linear activation function\n",
    "LEARNING_RATE = 1e-4 # start with a huge lr to converge fast\n",
    "REDUCE_LR_ON_PLAEAU_PATIENCE = 5\n",
    "DECAY_FACTOR = 0.7 # Define a learning rate decay for the ReduceLROnPlateau callback\n",
    "POLY_LR_DECAY = False\n",
    "MIN_LR = 1e-12 # minimal lr, smaller lr does not improve the model\n",
    "DROPOUT_min = 0.3 # lower dropout at the shallow layers\n",
    "DROPOUT_max = 0.5 # higher dropout at the deep layers\n",
    "\n",
    "# Callback params\n",
    "MONITOR_FUNCTION = 'loss'\n",
    "MONITOR_MODE = 'min'\n",
    "SAVE_MODEL_FUNCTION = 'loss'\n",
    "SAVE_MODEL_MODE = 'min'\n",
    "MODEL_PATIENCE = 20\n",
    "SAVE_LEARNING_PROGRESS_AS_TF = True\n",
    "\n",
    "# Generator and Augmentation params\n",
    "BORDER_MODE = cv2.BORDER_REFLECT_101 # border mode for the data generation\n",
    "IMG_INTERPOLATION = cv2.INTER_LINEAR # image interpolation in the genarator\n",
    "MSK_INTERPOLATION = cv2.INTER_NEAREST # mask interpolation in the generator\n",
    "AUGMENT = True # a compose of 2D augmentation (grid distortion, 90degree rotation, brightness and shift)\n",
    "AUGMENT_PROB = 0.8\n",
    "AUGMENT_PHASES = True\n",
    "AUGMENT_PHASES_RANGE = (-3,3)\n",
    "REPEAT_ONEHOT = True\n",
    "SHUFFLE = True\n",
    "RESAMPLE = True\n",
    "HIST_MATCHING = True\n",
    "SCALER = 'MinMax' # MinMax, Standard or Robust\n",
    "# We define 5 target phases and a background phase for the pad/empty volumes \n",
    "PHASES = len(['ED#', 'MS#', 'ES#', 'PF#', 'MD#']) # skipped 'pad backround manually added', due to repeating\n",
    "TARGET_SMOOTHING = True\n",
    "SMOOTHING_KERNEL_SIZE = 12\n",
    "SMOOTHING_LOWER_BORDER = 1\n",
    "SMOOTHING_UPPER_BORDER = 5\n",
    "SMOOTHING_WEIGHT_CORRECT = 10\n",
    "config = init_config(config=locals(), save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Creating directory /mnt/ssd/git/dynamic-cmr-models/logs/cv_baseline_batchmidhistmatch\n",
      "2021-03-15 14:26:40,672 INFO -------------------- Start --------------------\n",
      "2021-03-15 14:26:40,672 INFO Working directory: /mnt/ssd/git/dynamic-cmr-models.\n",
      "2021-03-15 14:26:40,672 INFO Log file: ./logs/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0.log\n",
      "2021-03-15 14:26:40,673 INFO Log level for console: INFO\n",
      "2021-03-15 14:26:40,673 INFO Is built with tensorflow: True\n",
      "2021-03-15 14:26:40,738 INFO Visible devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'), PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/gpu:0', '/gpu:1']\n",
      "{'GPU_IDS': '0,1', 'GPUS': ['/gpu:0', '/gpu:1'], 'SEED': 42, 'EXPERIMENT': 'cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0', 'EXPERIMENTS_ROOT': 'exp/', 'EXP_PATH': 'exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26', 'MODEL_PATH': 'exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/model', 'TENSORBOARD_PATH': 'exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/tensorboard_logs', 'CONFIG_PATH': 'exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/config', 'HISTORY_PATH': 'exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/history', 'DATA_PATH_SAX': '/mnt/ssd/data/gcn/02_imported_4D_unfiltered/SAX/', 'DF_FOLDS': '/mnt/ssd/data/gcn/02_imported_4D_unfiltered/df_kfold.csv', 'DF_META': '/mnt/ssd/data/gcn/02_imported_4D_unfiltered/SAx_3D_dicomTags_phase', 'FOLD': 0, 'BATCHSIZE': 8, 'GENERATOR_WORKER': 8, 'EPOCHS': 100, 'DIM': [8, 64, 64], 'T_SHAPE': 36, 'SPACING': [8, 3, 3], 'DEPTH': 4, 'FILTERS': 32, 'M_POOL': [1, 2, 2], 'F_SIZE': [3, 3, 3], 'BN_FIRST': False, 'BATCH_NORMALISATION': True, 'PAD': 'same', 'KERNEL_INIT': 'he_normal', 'OPTIMIZER': 'adam', 'ACTIVATION': 'relu', 'LEARNING_RATE': 0.0001, 'REDUCE_LR_ON_PLAEAU_PATIENCE': 5, 'DECAY_FACTOR': 0.7, 'POLY_LR_DECAY': False, 'MIN_LR': 1e-12, 'MONITOR_FUNCTION': 'loss', 'MONITOR_MODE': 'min', 'SAVE_MODEL_FUNCTION': 'loss', 'SAVE_MODEL_MODE': 'min', 'MODEL_PATIENCE': 20, 'SAVE_LEARNING_PROGRESS_AS_TF': True, 'BORDER_MODE': 4, 'IMG_INTERPOLATION': 1, 'MSK_INTERPOLATION': 0, 'AUGMENT': True, 'AUGMENT_PROB': 0.8, 'AUGMENT_PHASES': True, 'AUGMENT_PHASES_RANGE': (-3, 3), 'REPEAT_ONEHOT': True, 'SHUFFLE': True, 'RESAMPLE': True, 'HIST_MATCHING': True, 'SCALER': 'MinMax', 'PHASES': 5, 'TARGET_SMOOTHING': True, 'SMOOTHING_KERNEL_SIZE': 12, 'SMOOTHING_LOWER_BORDER': 1, 'SMOOTHING_UPPER_BORDER': 5, 'SMOOTHING_WEIGHT_CORRECT': 10, 'TENSORBOARD_LOG_DIR': 'reports/tensorboard_logs/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-15 14:26:41,409 INFO Local devices: \n",
      " [name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1901972386088241266\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 3915880477172769107\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16189688774008697041\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7107685360027888304\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 23080925952\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15243171246918203115\n",
      "physical_device_desc: \"device: 0, name: TITAN RTX, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 23561682304\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9685695225687988372\n",
      "physical_device_desc: \"device: 1, name: TITAN RTX, pci bus id: 0000:02:00.0, compute capability: 7.5\"\n",
      "]\n",
      "2021-03-15 14:26:41,410 INFO no files found, try to load with clean.nrrd/mask.nrrd pattern\n",
      "2021-03-15 14:26:41,417 INFO Found 278 images/masks in /mnt/ssd/data/gcn/02_imported_4D_unfiltered/SAX/\n",
      "2021-03-15 14:26:41,418 INFO Patients train: 209\n",
      "2021-03-15 14:26:41,430 INFO Selected 209 of 278 files with 209 of 279 patients for training fold 0\n",
      "2021-03-15 14:26:41,431 INFO SAX train CMR: 209, SAX train masks: 209\n",
      "2021-03-15 14:26:41,431 INFO SAX val CMR: 69, SAX val masks: 69\n",
      "2021-03-15 14:26:41,445 INFO Check if we find the patient ID and phase mapping for all: 278 files.\n",
      "2021-03-15 14:26:41,717 INFO Done!\n",
      "2021-03-15 14:26:41,722 INFO Create DataGenerator\n",
      "2021-03-15 14:26:41,723 INFO Datagenerator created with: \n",
      " shape: [8, 64, 64]\n",
      " spacing: [8, 3, 3]\n",
      " batchsize: 8\n",
      " Scaler: MinMax\n",
      " Images: 209 \n",
      " Augment: True \n",
      " Thread workers: 8\n",
      "2021-03-15 14:26:41,723 INFO Data will be augmented (shift,scale and rotate) with albumentation\n",
      "2021-03-15 14:26:41,737 INFO Smoothing kernel: \n",
      "[ 1.   1.8  2.6  3.4  4.2  5.  10.   5.   4.2  3.4  2.6  1.8  1. ]\n",
      "2021-03-15 14:26:41,737 INFO Temporal phase augmentation: \n",
      "True\n",
      "Repeat volume: \n",
      "True\n",
      "2021-03-15 14:26:41,782 INFO Create DataGenerator\n",
      "2021-03-15 14:26:41,782 INFO Datagenerator created with: \n",
      " shape: [8, 64, 64]\n",
      " spacing: [8, 3, 3]\n",
      " batchsize: 8\n",
      " Scaler: MinMax\n",
      " Images: 69 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-03-15 14:26:41,783 INFO No augmentation\n",
      "2021-03-15 14:26:41,795 INFO Smoothing kernel: \n",
      "[ 1.   1.8  2.6  3.4  4.2  5.  10.   5.   4.2  3.4  2.6  1.8  1. ]\n",
      "2021-03-15 14:26:41,796 INFO Temporal phase augmentation: \n",
      "False\n",
      "Repeat volume: \n",
      "True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after the temporal encoder\n",
      "(None, 36, 8, 4, 4, 512)\n",
      "Shape after GAP\n",
      "(None, 36, 512)\n",
      "Shape after Bi-LSTM layer\n",
      "(None, 36, 512)\n",
      "Shape after final conv layer\n",
      "(None, 36, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-15 14:26:47,269 INFO feed 4 Tensorboard is ready\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 1.2404 - mse_wrapper: 1.2404 - ca_wrapper: 0.3518 - meandiff: 16.9279"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-15 14:28:50,947 INFO (4, 2, 36, 5)\n",
      "2021-03-15 14:28:51,741 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: loss improved from inf to 1.24043, saving model to exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/model/model.h5\n",
      "26/26 [==============================] - 89s 3s/step - loss: 1.2404 - mse_wrapper: 1.2404 - ca_wrapper: 0.3518 - meandiff: 16.9279 - val_loss: 1.8908 - val_mse_wrapper: 1.8908 - val_ca_wrapper: 0.2934 - val_meandiff: 14.5156 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.8794 - mse_wrapper: 0.8794 - ca_wrapper: 0.5848 - meandiff: 8.8606"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-15 14:30:22,415 INFO (4, 2, 36, 5)\n",
      "2021-03-15 14:30:22,962 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: loss improved from 1.24043 to 0.87935, saving model to exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/model/model.h5\n",
      "26/26 [==============================] - 88s 3s/step - loss: 0.8794 - mse_wrapper: 0.8794 - ca_wrapper: 0.5848 - meandiff: 8.8606 - val_loss: 1.9368 - val_mse_wrapper: 1.9368 - val_ca_wrapper: 0.5985 - val_meandiff: 8.8906 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.7565 - mse_wrapper: 0.7565 - ca_wrapper: 0.6745 - meandiff: 7.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-15 14:31:54,338 INFO (4, 2, 36, 5)\n",
      "2021-03-15 14:31:54,866 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: loss improved from 0.87935 to 0.75651, saving model to exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/model/model.h5\n",
      "26/26 [==============================] - 88s 3s/step - loss: 0.7565 - mse_wrapper: 0.7565 - ca_wrapper: 0.6745 - meandiff: 7.8750 - val_loss: 1.1108 - val_mse_wrapper: 1.1108 - val_ca_wrapper: 0.6940 - val_meandiff: 8.7188 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.6873 - mse_wrapper: 0.6873 - ca_wrapper: 0.7242 - meandiff: 7.0577"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-15 14:33:19,830 INFO (4, 2, 36, 5)\n",
      "2021-03-15 14:33:20,353 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: loss improved from 0.75651 to 0.68726, saving model to exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/model/model.h5\n",
      "26/26 [==============================] - 83s 3s/step - loss: 0.6873 - mse_wrapper: 0.6873 - ca_wrapper: 0.7242 - meandiff: 7.0577 - val_loss: 1.3837 - val_mse_wrapper: 1.3837 - val_ca_wrapper: 0.6984 - val_meandiff: 6.1875 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.6255 - mse_wrapper: 0.6255 - ca_wrapper: 0.7588 - meandiff: 6.1394\n",
      "Epoch 00005: loss improved from 0.68726 to 0.62555, saving model to exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/model/model.h5\n",
      "26/26 [==============================] - 87s 3s/step - loss: 0.6255 - mse_wrapper: 0.6255 - ca_wrapper: 0.7588 - meandiff: 6.1394 - val_loss: 1.3484 - val_mse_wrapper: 1.3484 - val_ca_wrapper: 0.6128 - val_meandiff: 6.5469 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.5982 - mse_wrapper: 0.5982 - ca_wrapper: 0.7664 - meandiff: 5.8510"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-15 14:36:21,883 INFO (4, 2, 36, 5)\n",
      "2021-03-15 14:36:22,401 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: loss improved from 0.62555 to 0.59824, saving model to exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/model/model.h5\n",
      "26/26 [==============================] - 85s 3s/step - loss: 0.5982 - mse_wrapper: 0.5982 - ca_wrapper: 0.7664 - meandiff: 5.8510 - val_loss: 1.1292 - val_mse_wrapper: 1.1292 - val_ca_wrapper: 0.7478 - val_meandiff: 4.8750 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.5733 - mse_wrapper: 0.5733 - ca_wrapper: 0.7756 - meandiff: 5.2163\n",
      "Epoch 00007: loss improved from 0.59824 to 0.57333, saving model to exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/model/model.h5\n",
      "26/26 [==============================] - 82s 3s/step - loss: 0.5733 - mse_wrapper: 0.5733 - ca_wrapper: 0.7756 - meandiff: 5.2163 - val_loss: 1.8507 - val_mse_wrapper: 1.8507 - val_ca_wrapper: 0.6276 - val_meandiff: 6.7656 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.5711 - mse_wrapper: 0.5711 - ca_wrapper: 0.7758 - meandiff: 5.8413"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-15 14:39:20,941 INFO (4, 2, 36, 5)\n",
      "2021-03-15 14:39:21,461 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: loss improved from 0.57333 to 0.57115, saving model to exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/model/model.h5\n",
      "26/26 [==============================] - 82s 3s/step - loss: 0.5711 - mse_wrapper: 0.5711 - ca_wrapper: 0.7758 - meandiff: 5.8413 - val_loss: 1.2292 - val_mse_wrapper: 1.2292 - val_ca_wrapper: 0.7344 - val_meandiff: 4.6094 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.5719 - mse_wrapper: 0.5719 - ca_wrapper: 0.7667 - meandiff: 5.3413\n",
      "Epoch 00009: loss did not improve from 0.57115\n",
      "26/26 [==============================] - 84s 3s/step - loss: 0.5719 - mse_wrapper: 0.5719 - ca_wrapper: 0.7667 - meandiff: 5.3413 - val_loss: 0.9327 - val_mse_wrapper: 0.9327 - val_ca_wrapper: 0.7344 - val_meandiff: 5.1406 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.5436 - mse_wrapper: 0.5436 - ca_wrapper: 0.7906 - meandiff: 4.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-15 14:42:16,561 INFO (4, 2, 36, 5)\n",
      "2021-03-15 14:42:17,117 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: loss improved from 0.57115 to 0.54357, saving model to exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/model/model.h5\n",
      "26/26 [==============================] - 85s 3s/step - loss: 0.5436 - mse_wrapper: 0.5436 - ca_wrapper: 0.7906 - meandiff: 4.8750 - val_loss: 1.0055 - val_mse_wrapper: 1.0055 - val_ca_wrapper: 0.7526 - val_meandiff: 4.6250 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.5248 - mse_wrapper: 0.5248 - ca_wrapper: 0.7882 - meandiff: 5.1010\n",
      "Epoch 00011: loss improved from 0.54357 to 0.52484, saving model to exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/model/model.h5\n",
      "26/26 [==============================] - 83s 3s/step - loss: 0.5248 - mse_wrapper: 0.5248 - ca_wrapper: 0.7882 - meandiff: 5.1010 - val_loss: 0.7117 - val_mse_wrapper: 0.7117 - val_ca_wrapper: 0.7778 - val_meandiff: 4.3438 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.5096 - mse_wrapper: 0.5096 - ca_wrapper: 0.8057 - meandiff: 4.5144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-15 14:45:13,621 INFO (4, 2, 36, 5)\n",
      "2021-03-15 14:45:14,158 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00012: loss improved from 0.52484 to 0.50964, saving model to exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/model/model.h5\n",
      "26/26 [==============================] - 87s 3s/step - loss: 0.5096 - mse_wrapper: 0.5096 - ca_wrapper: 0.8057 - meandiff: 4.5144 - val_loss: 0.9840 - val_mse_wrapper: 0.9840 - val_ca_wrapper: 0.7643 - val_meandiff: 4.1094 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.5121 - mse_wrapper: 0.5121 - ca_wrapper: 0.8001 - meandiff: 4.2981\n",
      "Epoch 00013: loss did not improve from 0.50964\n",
      "26/26 [==============================] - 82s 3s/step - loss: 0.5121 - mse_wrapper: 0.5121 - ca_wrapper: 0.8001 - meandiff: 4.2981 - val_loss: 0.8295 - val_mse_wrapper: 0.8295 - val_ca_wrapper: 0.7635 - val_meandiff: 4.0781 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.5088 - mse_wrapper: 0.5088 - ca_wrapper: 0.8048 - meandiff: 4.5096"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-15 14:48:09,317 INFO (4, 2, 36, 5)\n",
      "2021-03-15 14:48:09,839 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: loss improved from 0.50964 to 0.50877, saving model to exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/model/model.h5\n",
      "26/26 [==============================] - 87s 3s/step - loss: 0.5088 - mse_wrapper: 0.5088 - ca_wrapper: 0.8048 - meandiff: 4.5096 - val_loss: 0.7514 - val_mse_wrapper: 0.7514 - val_ca_wrapper: 0.7817 - val_meandiff: 4.1875 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4984 - mse_wrapper: 0.4984 - ca_wrapper: 0.8101 - meandiff: 4.5577\n",
      "Epoch 00015: loss improved from 0.50877 to 0.49840, saving model to exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/model/model.h5\n",
      "26/26 [==============================] - 80s 3s/step - loss: 0.4984 - mse_wrapper: 0.4984 - ca_wrapper: 0.8101 - meandiff: 4.5577 - val_loss: 0.8395 - val_mse_wrapper: 0.8395 - val_ca_wrapper: 0.7617 - val_meandiff: 4.2188 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4998 - mse_wrapper: 0.4998 - ca_wrapper: 0.8050 - meandiff: 4.4567"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-15 14:50:58,381 INFO (4, 2, 36, 5)\n",
      "2021-03-15 14:50:58,916 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00016: loss did not improve from 0.49840\n",
      "26/26 [==============================] - 81s 3s/step - loss: 0.4998 - mse_wrapper: 0.4998 - ca_wrapper: 0.8050 - meandiff: 4.4567 - val_loss: 0.8240 - val_mse_wrapper: 0.8240 - val_ca_wrapper: 0.7964 - val_meandiff: 3.8125 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4795 - mse_wrapper: 0.4795 - ca_wrapper: 0.8121 - meandiff: 4.2404\n",
      "Epoch 00017: loss improved from 0.49840 to 0.47949, saving model to exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/model/model.h5\n",
      "26/26 [==============================] - 82s 3s/step - loss: 0.4795 - mse_wrapper: 0.4795 - ca_wrapper: 0.8121 - meandiff: 4.2404 - val_loss: 0.6124 - val_mse_wrapper: 0.6124 - val_ca_wrapper: 0.7917 - val_meandiff: 4.8438 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4856 - mse_wrapper: 0.4856 - ca_wrapper: 0.8165 - meandiff: 4.2981"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-15 14:53:53,753 INFO (4, 2, 36, 5)\n",
      "2021-03-15 14:53:54,282 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00018: loss did not improve from 0.47949\n",
      "26/26 [==============================] - 86s 3s/step - loss: 0.4856 - mse_wrapper: 0.4856 - ca_wrapper: 0.8165 - meandiff: 4.2981 - val_loss: 0.8486 - val_mse_wrapper: 0.8486 - val_ca_wrapper: 0.7834 - val_meandiff: 3.8125 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4753 - mse_wrapper: 0.4753 - ca_wrapper: 0.8117 - meandiff: 4.4471\n",
      "Epoch 00019: loss improved from 0.47949 to 0.47527, saving model to exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/model/model.h5\n",
      "26/26 [==============================] - 84s 3s/step - loss: 0.4753 - mse_wrapper: 0.4753 - ca_wrapper: 0.8117 - meandiff: 4.4471 - val_loss: 1.0738 - val_mse_wrapper: 1.0738 - val_ca_wrapper: 0.7826 - val_meandiff: 3.5312 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4577 - mse_wrapper: 0.4577 - ca_wrapper: 0.8177 - meandiff: 4.0385"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-15 14:56:52,442 INFO (4, 2, 36, 5)\n",
      "2021-03-15 14:56:53,016 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00020: loss improved from 0.47527 to 0.45772, saving model to exp/cv_baseline_batchmidhistmatch/8_64_64__8_2_2_4tenc_conv1_MSE_NOnorm_augshiftrot_taug_3_batch8_f0/2021-03-15_14_26/model/model.h5\n",
      "26/26 [==============================] - 88s 3s/step - loss: 0.4577 - mse_wrapper: 0.4577 - ca_wrapper: 0.8177 - meandiff: 4.0385 - val_loss: 0.7969 - val_mse_wrapper: 0.7969 - val_ca_wrapper: 0.7995 - val_meandiff: 4.6562 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "16/26 [=================>............] - ETA: 28s - loss: 0.4511 - mse_wrapper: 0.4511 - ca_wrapper: 0.8290 - meandiff: 3.9844"
     ]
    }
   ],
   "source": [
    "from src.models.train_model import train_fold\n",
    "\n",
    "folds = [i for i in range(0, 1, 1)]\n",
    "\n",
    "for f in folds:\n",
    "    info('starting fold: {}'.format(f))\n",
    "    config_ = config.copy()\n",
    "    config_['FOLD'] = f\n",
    "    train_fold(config_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'1': 'a'},)\n"
     ]
    }
   ],
   "source": [
    "def foo(*kwargs):\n",
    "    print(kwargs)\n",
    "    \n",
    "    \n",
    "cfg = {}\n",
    "cfg['1'] = 'a'\n",
    "\n",
    "foo(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcmr",
   "language": "python",
   "name": "dcmr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
