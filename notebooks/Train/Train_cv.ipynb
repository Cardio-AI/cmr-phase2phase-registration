{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search for root_dir and set working directory\n",
      "Working directory set to: /mnt/ssd/git/dynamic-cmr-models\n",
      "['/gpu:0', '/gpu:1']\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------define logging and working directory\n",
    "from ProjectRoot import change_wd_to_project_root\n",
    "change_wd_to_project_root()\n",
    "from src.utils.Tensorflow_helper import choose_gpu_by_id\n",
    "# ------------------------------------------define GPU id/s to use\n",
    "GPU_IDS = '0,1'\n",
    "GPUS = choose_gpu_by_id(GPU_IDS)\n",
    "print(GPUS)\n",
    "# ------------------------------------------jupyter magic config\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# ------------------------------------------ import helpers\n",
    "# this should import glob, os, and many other standard libs\n",
    "# local imports\n",
    "from src.utils.Notebook_imports import *\n",
    "from src.utils.Utils_io import Console_and_file_logger, init_config\n",
    "\n",
    "# import external libs\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "EXPERIMENT = 'cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8'\n",
    "#EXPERIMENT = 'baseline_label_transpose_smooth05/36_5_BiLSTM32_NoBn_conv5_size1_CCE_NOphaseaug_NOaug_b8'\n",
    "# EXPERIMENT = 'mased_scores/36_5_BiLSTM32_NoBn_conv5_size1_CCE_NOphaseaug_shift_rotate_reflectbordersgridaug'\n",
    "timestemp = str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M\")) # ad a timestep to each project to make repeated experiments unique\n",
    "\n",
    "EXPERIMENTS_ROOT = 'exp/'\n",
    "EXP_PATH = os.path.join(EXPERIMENTS_ROOT, EXPERIMENT, timestemp)\n",
    "MODEL_PATH = os.path.join(EXP_PATH, 'model', )\n",
    "TENSORBOARD_PATH = os.path.join(EXP_PATH, 'tensorboard_logs')\n",
    "CONFIG_PATH = os.path.join(EXP_PATH,'config')\n",
    "HISTORY_PATH = os.path.join(EXP_PATH, 'history')\n",
    "ensure_dir(MODEL_PATH)\n",
    "ensure_dir(TENSORBOARD_PATH)\n",
    "ensure_dir(CONFIG_PATH)\n",
    "ensure_dir(HISTORY_PATH)\n",
    "\n",
    "# define the data paths and fold \n",
    "# first to the 4D Nrrd files, \n",
    "# second to a dataframe with a mapping of the Fold-number\n",
    "# Finally the path to the metadata\n",
    "DATA_PATH_SAX = '/mnt/ssd/data/gcn/02_imported_4D_unfiltered/SAX/'\n",
    "DF_FOLDS = '/mnt/ssd/data/gcn/02_imported_4D_unfiltered/df_kfold.csv'\n",
    "DF_META = '/mnt/ssd/data/gcn/02_imported_4D_unfiltered/SAx_3D_dicomTags_phase'\n",
    "FOLD = 0\n",
    "\n",
    "# General params\n",
    "SEED = 42 # define a seed for the generator shuffle\n",
    "BATCHSIZE = 8 # 32, 64, 24, 16, 1 for 3D use: 4\n",
    "GENERATOR_WORKER = BATCHSIZE # if not set, use batchsize\n",
    "EPOCHS = 50\n",
    "\n",
    "DIM = [8, 64, 64] # network input shape for spacing of 3, (z,y,x)\n",
    "T_SHAPE = 36\n",
    "SPACING = [8, 3, 3] # if resample, resample to this spacing, (z,y,x)\n",
    "\n",
    "# Model params\n",
    "DEPTH = 4 # depth of the encoder\n",
    "FILTERS = 32 # initial number of filters, will be doubled after each downsampling block\n",
    "M_POOL = [1, 2, 2]# size of max-pooling used for downsampling and upsampling\n",
    "F_SIZE = [3, 3, 3] # conv filter size\n",
    "BN_FIRST = False # decide if batch normalisation between conv and activation or afterwards\n",
    "BATCH_NORMALISATION = True # apply BN or not\n",
    "PAD = 'same' # padding strategy of the conv layers\n",
    "KERNEL_INIT = 'he_normal' # conv weight initialisation\n",
    "OPTIMIZER = 'adam' # Adam, Adagrad, RMSprop, Adadelta,  # https://keras.io/optimizers/\n",
    "ACTIVATION = 'relu' # tf.keras.layers.LeakyReLU(), relu or any other non linear activation function\n",
    "LEARNING_RATE = 1e-4 # start with a huge lr to converge fast\n",
    "REDUCE_LR_ON_PLAEAU_PATIENCE = 5\n",
    "DECAY_FACTOR = 0.7 # Define a learning rate decay for the ReduceLROnPlateau callback\n",
    "MIN_LR = 1e-12 # minimal lr, smaller lr does not improve the model\n",
    "DROPOUT_min = 0.3 # lower dropout at the shallow layers\n",
    "DROPOUT_max = 0.5 # higher dropout at the deep layers\n",
    "\n",
    "# Callback params\n",
    "MONITOR_FUNCTION = 'loss'\n",
    "MONITOR_MODE = 'min'\n",
    "SAVE_MODEL_FUNCTION = 'loss'\n",
    "SAVE_MODEL_MODE = 'min'\n",
    "MODEL_PATIENCE = 20\n",
    "SAVE_LEARNING_PROGRESS_AS_TF = True\n",
    "\n",
    "# Generator and Augmentation params\n",
    "BORDER_MODE = cv2.BORDER_REFLECT_101 # border mode for the data generation\n",
    "IMG_INTERPOLATION = cv2.INTER_LINEAR # image interpolation in the genarator\n",
    "MSK_INTERPOLATION = cv2.INTER_NEAREST # mask interpolation in the generator\n",
    "AUGMENT = True # a compose of 2D augmentation (grid distortion, 90degree rotation, brightness and shift)\n",
    "AUGMENT_PROB = 0.8\n",
    "AUGMENT_PHASES = False\n",
    "AUGMENT_PHASES_RANGE = (-18,18)\n",
    "REPEAT_ONEHOT = True\n",
    "SHUFFLE = True\n",
    "RESAMPLE = True\n",
    "SCALER = 'MinMax' # MinMax, Standard or Robust\n",
    "# We define 5 target phases and a background phase for the pad/empty volumes \n",
    "PHASES = len(['ED#', 'MS#', 'ES#', 'PF#', 'MD#']) # skipped 'pad backround manually added', due to repeating\n",
    "TARGET_SMOOTHING = True\n",
    "SMOOTHING_KERNEL_SIZE = 12\n",
    "SMOOTHING_LOWER_BORDER = 1\n",
    "SMOOTHING_UPPER_BORDER = 5\n",
    "SMOOTHING_WEIGHT_CORRECT = 10\n",
    "config = init_config(config=locals(), save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Creating directory /mnt/ssd/git/dynamic-cmr-models/logs/cv_baseline_NOtaug\n",
      "2021-03-03 19:42:53,420 INFO -------------------- Start --------------------\n",
      "2021-03-03 19:42:53,421 INFO Working directory: /mnt/ssd/git/dynamic-cmr-models.\n",
      "2021-03-03 19:42:53,421 INFO Log file: ./logs/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0.log\n",
      "2021-03-03 19:42:53,421 INFO Log level for console: INFO\n",
      "2021-03-03 19:42:53,422 INFO Is built with tensorflow: True\n",
      "2021-03-03 19:42:53,479 INFO Visible devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'), PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "2021-03-03 19:42:54,117 INFO Local devices: \n",
      " [name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17216759210989006534\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 857925155891981585\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13913984899106745554\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16406373393640474674\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 23102240896\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16624711506255307162\n",
      "physical_device_desc: \"device: 0, name: TITAN RTX, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 23561682304\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15221365168495526007\n",
      "physical_device_desc: \"device: 1, name: TITAN RTX, pci bus id: 0000:02:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/gpu:0', '/gpu:1']\n",
      "{'GPU_IDS': '0,1', 'GPUS': ['/gpu:0', '/gpu:1'], 'SEED': 42, 'EXPERIMENT': 'cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0', 'EXPERIMENTS_ROOT': 'exp/', 'EXP_PATH': 'exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42', 'MODEL_PATH': 'exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model', 'TENSORBOARD_PATH': 'exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/tensorboard_logs', 'CONFIG_PATH': 'exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/config', 'HISTORY_PATH': 'exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/history', 'DATA_PATH_SAX': '/mnt/ssd/data/gcn/02_imported_4D_unfiltered/SAX/', 'DF_FOLDS': '/mnt/ssd/data/gcn/02_imported_4D_unfiltered/df_kfold.csv', 'DF_META': '/mnt/ssd/data/gcn/02_imported_4D_unfiltered/SAx_3D_dicomTags_phase', 'FOLD': 0, 'BATCHSIZE': 8, 'GENERATOR_WORKER': 8, 'EPOCHS': 50, 'DIM': [8, 64, 64], 'T_SHAPE': 36, 'SPACING': [8, 3, 3], 'DEPTH': 4, 'FILTERS': 32, 'M_POOL': [1, 2, 2], 'F_SIZE': [3, 3, 3], 'BN_FIRST': False, 'BATCH_NORMALISATION': True, 'PAD': 'same', 'KERNEL_INIT': 'he_normal', 'OPTIMIZER': 'adam', 'ACTIVATION': 'relu', 'LEARNING_RATE': 0.0001, 'REDUCE_LR_ON_PLAEAU_PATIENCE': 5, 'DECAY_FACTOR': 0.7, 'MIN_LR': 1e-12, 'MONITOR_FUNCTION': 'loss', 'MONITOR_MODE': 'min', 'SAVE_MODEL_FUNCTION': 'loss', 'SAVE_MODEL_MODE': 'min', 'MODEL_PATIENCE': 20, 'SAVE_LEARNING_PROGRESS_AS_TF': True, 'BORDER_MODE': 4, 'IMG_INTERPOLATION': 1, 'MSK_INTERPOLATION': 0, 'AUGMENT': True, 'AUGMENT_PROB': 0.8, 'AUGMENT_PHASES': False, 'AUGMENT_PHASES_RANGE': (-18, 18), 'REPEAT_ONEHOT': True, 'SHUFFLE': True, 'RESAMPLE': True, 'SCALER': 'MinMax', 'PHASES': 5, 'TARGET_SMOOTHING': True, 'SMOOTHING_KERNEL_SIZE': 12, 'SMOOTHING_LOWER_BORDER': 1, 'SMOOTHING_UPPER_BORDER': 5, 'SMOOTHING_WEIGHT_CORRECT': 10, 'TENSORBOARD_LOG_DIR': 'reports/tensorboard_logs/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-03 19:42:54,119 INFO no files found, try to load with clean.nrrd/mask.nrrd pattern\n",
      "2021-03-03 19:42:54,126 INFO Found 278 images/masks in /mnt/ssd/data/gcn/02_imported_4D_unfiltered/SAX/\n",
      "2021-03-03 19:42:54,126 INFO Patients train: 209\n",
      "2021-03-03 19:42:54,137 INFO Selected 209 of 278 files with 209 of 279 patients for training fold 0\n",
      "2021-03-03 19:42:54,138 INFO SAX train CMR: 209, SAX train masks: 209\n",
      "2021-03-03 19:42:54,138 INFO SAX val CMR: 69, SAX val masks: 69\n",
      "2021-03-03 19:42:54,151 INFO Check if we find the patient ID and phase mapping for all: 278 files.\n",
      "2021-03-03 19:42:54,426 INFO Done!\n",
      "2021-03-03 19:42:54,427 INFO Create DataGenerator\n",
      "2021-03-03 19:42:54,428 INFO Datagenerator created with: \n",
      " shape: [8, 64, 64]\n",
      " spacing: [8, 3, 3]\n",
      " batchsize: 8\n",
      " Scaler: MinMax\n",
      " Images: 209 \n",
      " Augment: True \n",
      " Thread workers: 8\n",
      "2021-03-03 19:42:54,428 INFO Data will be augmented (shift,scale and rotate) with albumentation\n",
      "2021-03-03 19:42:54,442 INFO Smoothing kernel: \n",
      "[ 1.   1.8  2.6  3.4  4.2  5.  10.   5.   4.2  3.4  2.6  1.8  1. ]\n",
      "2021-03-03 19:42:54,442 INFO Temporal phase augmentation: \n",
      "False\n",
      "Repeat volume: \n",
      "True\n",
      "2021-03-03 19:42:54,443 INFO Create DataGenerator\n",
      "2021-03-03 19:42:54,443 INFO Datagenerator created with: \n",
      " shape: [8, 64, 64]\n",
      " spacing: [8, 3, 3]\n",
      " batchsize: 8\n",
      " Scaler: MinMax\n",
      " Images: 69 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-03-03 19:42:54,444 INFO No augmentation\n",
      "2021-03-03 19:42:54,457 INFO Smoothing kernel: \n",
      "[ 1.   1.8  2.6  3.4  4.2  5.  10.   5.   4.2  3.4  2.6  1.8  1. ]\n",
      "2021-03-03 19:42:54,457 INFO Temporal phase augmentation: \n",
      "False\n",
      "Repeat volume: \n",
      "True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after the temporal encoder\n",
      "(None, 36, 8, 4, 4, 512)\n",
      "Shape after GAP\n",
      "(None, 36, 512)\n",
      "Shape after Bi-LSTM layer\n",
      "(None, 36, 512)\n",
      "Shape after final conv layer\n",
      "(None, 36, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-03 19:42:58,944 INFO feed 4 Tensorboard is ready\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 1.0511 - mse_wrapper: 1.0511 - ca_wrapper: 0.4729 - meandiff: 10.6394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-03 19:44:05,941 INFO (4, 2, 36, 5)\n",
      "2021-03-03 19:44:06,503 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: loss improved from inf to 1.05106, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 36s 1s/step - loss: 1.0511 - mse_wrapper: 1.0511 - ca_wrapper: 0.4729 - meandiff: 10.6394 - val_loss: 2.4659 - val_mse_wrapper: 2.4659 - val_ca_wrapper: 0.2305 - val_meandiff: 16.6562 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.7577 - mse_wrapper: 0.7577 - ca_wrapper: 0.6573 - meandiff: 6.7548"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-03 19:44:39,088 INFO (4, 2, 36, 5)\n",
      "2021-03-03 19:44:39,645 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: loss improved from 1.05106 to 0.75770, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.7577 - mse_wrapper: 0.7577 - ca_wrapper: 0.6573 - meandiff: 6.7548 - val_loss: 1.5408 - val_mse_wrapper: 1.5408 - val_ca_wrapper: 0.4366 - val_meandiff: 10.0156 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.6703 - mse_wrapper: 0.6703 - ca_wrapper: 0.7196 - meandiff: 5.8173"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-03 19:45:12,433 INFO (4, 2, 36, 5)\n",
      "2021-03-03 19:45:12,993 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: loss improved from 0.75770 to 0.67029, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.6703 - mse_wrapper: 0.6703 - ca_wrapper: 0.7196 - meandiff: 5.8173 - val_loss: 1.0181 - val_mse_wrapper: 1.0181 - val_ca_wrapper: 0.6762 - val_meandiff: 5.9688 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.6152 - mse_wrapper: 0.6152 - ca_wrapper: 0.7576 - meandiff: 5.3413"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-03 19:45:45,848 INFO (4, 2, 36, 5)\n",
      "2021-03-03 19:45:46,427 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: loss improved from 0.67029 to 0.61524, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.6152 - mse_wrapper: 0.6152 - ca_wrapper: 0.7576 - meandiff: 5.3413 - val_loss: 0.9838 - val_mse_wrapper: 0.9838 - val_ca_wrapper: 0.7231 - val_meandiff: 5.9062 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.5791 - mse_wrapper: 0.5791 - ca_wrapper: 0.7635 - meandiff: 5.0529\n",
      "Epoch 00005: loss improved from 0.61524 to 0.57906, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.5791 - mse_wrapper: 0.5791 - ca_wrapper: 0.7635 - meandiff: 5.0529 - val_loss: 0.9067 - val_mse_wrapper: 0.9067 - val_ca_wrapper: 0.7457 - val_meandiff: 5.2656 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.5497 - mse_wrapper: 0.5497 - ca_wrapper: 0.7835 - meandiff: 4.9856"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-03 19:46:52,768 INFO (4, 2, 36, 5)\n",
      "2021-03-03 19:46:53,291 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: loss improved from 0.57906 to 0.54969, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.5497 - mse_wrapper: 0.5497 - ca_wrapper: 0.7835 - meandiff: 4.9856 - val_loss: 0.6134 - val_mse_wrapper: 0.6134 - val_ca_wrapper: 0.7930 - val_meandiff: 4.7188 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.5227 - mse_wrapper: 0.5227 - ca_wrapper: 0.7874 - meandiff: 4.8798\n",
      "Epoch 00007: loss improved from 0.54969 to 0.52268, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.5227 - mse_wrapper: 0.5227 - ca_wrapper: 0.7874 - meandiff: 4.8798 - val_loss: 0.8178 - val_mse_wrapper: 0.8178 - val_ca_wrapper: 0.7365 - val_meandiff: 5.2656 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.5256 - mse_wrapper: 0.5256 - ca_wrapper: 0.7885 - meandiff: 4.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-03 19:48:02,420 INFO (4, 2, 36, 5)\n",
      "2021-03-03 19:48:02,965 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: loss did not improve from 0.52268\n",
      "26/26 [==============================] - 34s 1s/step - loss: 0.5256 - mse_wrapper: 0.5256 - ca_wrapper: 0.7885 - meandiff: 4.5000 - val_loss: 0.8605 - val_mse_wrapper: 0.8605 - val_ca_wrapper: 0.7817 - val_meandiff: 4.3906 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4958 - mse_wrapper: 0.4958 - ca_wrapper: 0.7951 - meandiff: 4.4279\n",
      "Epoch 00009: loss improved from 0.52268 to 0.49584, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.4958 - mse_wrapper: 0.4958 - ca_wrapper: 0.7951 - meandiff: 4.4279 - val_loss: 0.6236 - val_mse_wrapper: 0.6236 - val_ca_wrapper: 0.7782 - val_meandiff: 4.2500 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4898 - mse_wrapper: 0.4898 - ca_wrapper: 0.8041 - meandiff: 4.3029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-03 19:49:13,373 INFO (4, 2, 36, 5)\n",
      "2021-03-03 19:49:13,895 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: loss improved from 0.49584 to 0.48983, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 34s 1s/step - loss: 0.4898 - mse_wrapper: 0.4898 - ca_wrapper: 0.8041 - meandiff: 4.3029 - val_loss: 0.7171 - val_mse_wrapper: 0.7171 - val_ca_wrapper: 0.7912 - val_meandiff: 4.1250 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4764 - mse_wrapper: 0.4764 - ca_wrapper: 0.7997 - meandiff: 4.3510\n",
      "Epoch 00011: loss improved from 0.48983 to 0.47638, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.4764 - mse_wrapper: 0.4764 - ca_wrapper: 0.7997 - meandiff: 4.3510 - val_loss: 1.2873 - val_mse_wrapper: 1.2873 - val_ca_wrapper: 0.7010 - val_meandiff: 4.9219 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4653 - mse_wrapper: 0.4653 - ca_wrapper: 0.8150 - meandiff: 4.2452"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-03 19:50:23,922 INFO (4, 2, 36, 5)\n",
      "2021-03-03 19:50:24,457 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00012: loss improved from 0.47638 to 0.46535, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 34s 1s/step - loss: 0.4653 - mse_wrapper: 0.4653 - ca_wrapper: 0.8150 - meandiff: 4.2452 - val_loss: 0.8294 - val_mse_wrapper: 0.8294 - val_ca_wrapper: 0.7865 - val_meandiff: 4.5156 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4614 - mse_wrapper: 0.4614 - ca_wrapper: 0.8128 - meandiff: 4.0625\n",
      "Epoch 00013: loss improved from 0.46535 to 0.46136, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.4614 - mse_wrapper: 0.4614 - ca_wrapper: 0.8128 - meandiff: 4.0625 - val_loss: 0.8094 - val_mse_wrapper: 0.8094 - val_ca_wrapper: 0.7769 - val_meandiff: 4.1094 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4774 - mse_wrapper: 0.4774 - ca_wrapper: 0.8077 - meandiff: 4.1394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-03 19:51:35,273 INFO (4, 2, 36, 5)\n",
      "2021-03-03 19:51:35,815 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: loss did not improve from 0.46136\n",
      "26/26 [==============================] - 34s 1s/step - loss: 0.4774 - mse_wrapper: 0.4774 - ca_wrapper: 0.8077 - meandiff: 4.1394 - val_loss: 0.8151 - val_mse_wrapper: 0.8151 - val_ca_wrapper: 0.7769 - val_meandiff: 4.7969 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4516 - mse_wrapper: 0.4516 - ca_wrapper: 0.8190 - meandiff: 3.9423\n",
      "Epoch 00015: loss improved from 0.46136 to 0.45165, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.4516 - mse_wrapper: 0.4516 - ca_wrapper: 0.8190 - meandiff: 3.9423 - val_loss: 0.6248 - val_mse_wrapper: 0.6248 - val_ca_wrapper: 0.8008 - val_meandiff: 4.4375 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4387 - mse_wrapper: 0.4387 - ca_wrapper: 0.8202 - meandiff: 3.9856"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-03 19:52:45,737 INFO (4, 2, 36, 5)\n",
      "2021-03-03 19:52:46,277 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00016: loss improved from 0.45165 to 0.43866, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 34s 1s/step - loss: 0.4387 - mse_wrapper: 0.4387 - ca_wrapper: 0.8202 - meandiff: 3.9856 - val_loss: 0.8695 - val_mse_wrapper: 0.8695 - val_ca_wrapper: 0.7561 - val_meandiff: 4.5625 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4416 - mse_wrapper: 0.4416 - ca_wrapper: 0.8280 - meandiff: 3.9087\n",
      "Epoch 00017: loss did not improve from 0.43866\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.4416 - mse_wrapper: 0.4416 - ca_wrapper: 0.8280 - meandiff: 3.9087 - val_loss: 1.0032 - val_mse_wrapper: 1.0032 - val_ca_wrapper: 0.7096 - val_meandiff: 5.0000 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4318 - mse_wrapper: 0.4318 - ca_wrapper: 0.8249 - meandiff: 3.9519"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-03 19:53:56,052 INFO (4, 2, 36, 5)\n",
      "2021-03-03 19:53:56,623 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00018: loss improved from 0.43866 to 0.43177, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 34s 1s/step - loss: 0.4318 - mse_wrapper: 0.4318 - ca_wrapper: 0.8249 - meandiff: 3.9519 - val_loss: 0.6125 - val_mse_wrapper: 0.6125 - val_ca_wrapper: 0.8008 - val_meandiff: 4.7969 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4228 - mse_wrapper: 0.4228 - ca_wrapper: 0.8233 - meandiff: 3.9279\n",
      "Epoch 00019: loss improved from 0.43177 to 0.42283, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.4228 - mse_wrapper: 0.4228 - ca_wrapper: 0.8233 - meandiff: 3.9279 - val_loss: 0.8134 - val_mse_wrapper: 0.8134 - val_ca_wrapper: 0.8016 - val_meandiff: 4.8438 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4185 - mse_wrapper: 0.4185 - ca_wrapper: 0.8303 - meandiff: 3.7548"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-03 19:55:06,814 INFO (4, 2, 36, 5)\n",
      "2021-03-03 19:55:07,348 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00020: loss improved from 0.42283 to 0.41846, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 34s 1s/step - loss: 0.4185 - mse_wrapper: 0.4185 - ca_wrapper: 0.8303 - meandiff: 3.7548 - val_loss: 0.6766 - val_mse_wrapper: 0.6766 - val_ca_wrapper: 0.7973 - val_meandiff: 4.8281 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4231 - mse_wrapper: 0.4231 - ca_wrapper: 0.8228 - meandiff: 3.7548\n",
      "Epoch 00021: loss did not improve from 0.41846\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.4231 - mse_wrapper: 0.4231 - ca_wrapper: 0.8228 - meandiff: 3.7548 - val_loss: 0.7313 - val_mse_wrapper: 0.7313 - val_ca_wrapper: 0.7613 - val_meandiff: 4.9375 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4137 - mse_wrapper: 0.4137 - ca_wrapper: 0.8299 - meandiff: 3.8221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-03 19:56:17,832 INFO (4, 2, 36, 5)\n",
      "2021-03-03 19:56:18,390 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00022: loss improved from 0.41846 to 0.41375, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 35s 1s/step - loss: 0.4137 - mse_wrapper: 0.4137 - ca_wrapper: 0.8299 - meandiff: 3.8221 - val_loss: 0.6404 - val_mse_wrapper: 0.6404 - val_ca_wrapper: 0.8186 - val_meandiff: 4.4844 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4123 - mse_wrapper: 0.4123 - ca_wrapper: 0.8341 - meandiff: 3.9087\n",
      "Epoch 00023: loss improved from 0.41375 to 0.41228, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.4123 - mse_wrapper: 0.4123 - ca_wrapper: 0.8341 - meandiff: 3.9087 - val_loss: 0.6465 - val_mse_wrapper: 0.6465 - val_ca_wrapper: 0.8047 - val_meandiff: 4.2812 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4141 - mse_wrapper: 0.4141 - ca_wrapper: 0.8221 - meandiff: 3.9519"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-03 19:57:28,359 INFO (4, 2, 36, 5)\n",
      "2021-03-03 19:57:28,891 INFO (4, 2, 36, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: loss did not improve from 0.41228\n",
      "26/26 [==============================] - 34s 1s/step - loss: 0.4141 - mse_wrapper: 0.4141 - ca_wrapper: 0.8221 - meandiff: 3.9519 - val_loss: 0.9351 - val_mse_wrapper: 0.9351 - val_ca_wrapper: 0.7374 - val_meandiff: 4.4531 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4071 - mse_wrapper: 0.4071 - ca_wrapper: 0.8301 - meandiff: 3.8510\n",
      "Epoch 00025: loss improved from 0.41228 to 0.40706, saving model to exp/cv_baseline_NOtaug/8_64_64__8_3_3_4tenc_conv1_MSE_NOnorm_augshiftrot_NOtaug_3_batch8_f0/2021-03-03_19_42/model/model.h5\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.4071 - mse_wrapper: 0.4071 - ca_wrapper: 0.8301 - meandiff: 3.8510 - val_loss: 0.7152 - val_mse_wrapper: 0.7152 - val_ca_wrapper: 0.8108 - val_meandiff: 4.3281 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "19/26 [====================>.........] - ETA: 7s - loss: 0.4040 - mse_wrapper: 0.4040 - ca_wrapper: 0.8353 - meandiff: 3.8026"
     ]
    }
   ],
   "source": [
    "from src.models.train_model import train_fold\n",
    "\n",
    "folds = [i for i in range(0, 4, 1)]\n",
    "\n",
    "for f in folds:\n",
    "    info('starting fold: {}'.format(f))\n",
    "    config_ = config.copy()\n",
    "    config_['FOLD'] = f\n",
    "    train_fold(config_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcmr",
   "language": "python",
   "name": "dcmr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
