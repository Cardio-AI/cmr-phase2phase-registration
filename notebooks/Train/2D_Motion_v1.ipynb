{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search for root_dir and set working directory\n",
      "Working directory set to: /mnt/data/git/cardio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-10-10 08:50:07,824 INFO -------------------- Start --------------------\n",
      "2019-10-10 08:50:07,825 INFO Working directory: /mnt/data/git/cardio.\n",
      "2019-10-10 08:50:07,825 INFO Log file: ./logs/motion/2D/gcn.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpu(0)', 'gpu(1)']\n"
     ]
    }
   ],
   "source": [
    "# define logging and working directory\n",
    "from ProjectRoot import change_wd_to_project_root\n",
    "change_wd_to_project_root()\n",
    "from src.utils.notebook_imports import *\n",
    "from pyforest import *\n",
    "\n",
    "\n",
    "# define GPU id to use\n",
    "# 0 = 1080 Bus ID 2\n",
    "# 1 = Titan Bus ID 131\n",
    "# 2 = Titan Bus ID 132\n",
    "GPU_IDS = '0,1'\n",
    "current_gpu = choose_gpu_by_id(GPU_IDS)\n",
    "print(current_gpu)\n",
    "\n",
    "# jupyter magic config\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import helpers\n",
    "from src.utils.utils_io import Console_and_file_logger, init_config\n",
    "from src.visualization.visualize import show_2D_or_3D\n",
    "from src.data.dataset import get_img_msk_files_from_split_dir, load_acdc_files, get_train_data_from_df\n",
    "from src.data.generators import DataGenerator, get_samples\n",
    "from src.utils.unet_3d_metrics import weighted_dice_coefficient_loss\n",
    "from src.models.ModelManager import get_model\n",
    "from src.utils.KerasCallbacks import get_callbacks\n",
    "import src.utils.my_metrics as metr\n",
    "\n",
    "\n",
    "# define experiment name for report, model and log paths + filenames\n",
    "EXPERIMENT = 'motion/2D/gcn'\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# image params, change for different input data/architecture\n",
    "ARCHITECTURE = '2D' # 2D\n",
    "DIM = [224, 224]\n",
    "\n",
    "SPACING = [1.0,1.0] # used by sitk, opposite order than numpy or tensorflow!\n",
    "IMG_CHANNELS = 1\n",
    "MASK_VALUES = [0, 1, 2, 3]  \n",
    "MASK_CLASSES = len(MASK_VALUES)\n",
    "# Background = 0 = Y[:,:,0]\n",
    "# RV = 1 = Y[:,:,1] \n",
    "# Myo = 2 = Y[:,:,2] \n",
    "# LV = 3 = Y[:,:,3]\n",
    "AUGMENT = False\n",
    "SHUFFLE = True\n",
    "AUGMENT_GRID = False\n",
    "RESAMPLE = False\n",
    "\n",
    "# path params\n",
    "DATASET = 'gcn'\n",
    "\n",
    "MODEL_PATH = os.path.join(os.path.join('models', EXPERIMENT), str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "TENSORBOARD_LOG_DIR = os.path.join(os.path.join('reports/tensorboard_logs', EXPERIMENT),str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "CONFIG_PATH = os.path.join(os.path.join('reports/configs/',EXPERIMENT),str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "HISTORY_PATH = os.path.join(os.path.join('reports/history/',EXPERIMENT),str(now.strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "\n",
    "# training params\n",
    "GENERATOR_WORKER = 4 # if not set, use batchsize\n",
    "seed = 42\n",
    "BATCHSIZE =  2 # 32, 64, 24, 16, 1\n",
    "INITIAL_EPOCH = 0\n",
    "EPOCHS = 150\n",
    "FOLDS = 4\n",
    "EPOCHS_BETWEEN_CHECKPOINTS = 5\n",
    "MONITOR_FUNCTION = 'loss'\n",
    "MONITOR_MODE = 'min'\n",
    "SAVE_MODEL_FUNCTION = 'loss'\n",
    "SAVE_MODEL_MODE = 'min'\n",
    "\n",
    "# Network params\n",
    "OPTIMIZER = 'Adam'  # Adam, Adagrad, RMSprop, Adadelta,  # https://keras.io/optimizers/\n",
    "ACTIVATION = 'elu'  # 'elu' --> works well with binary_crossentropy and bce_dice_loss, relu does not work, it clips negative values, bse does return negative values\n",
    "LEARNING_RATE = 0.001\n",
    "DECAY = 0.0\n",
    "EPSILON = 1e-08\n",
    "DROPOUT_L1_L2 = 0.4 # higher dropout at the deeper layers\n",
    "DROPOUT_L3_L4 = 0.4\n",
    "DROPOUT_L5 = 0.5\n",
    "BATCH_NORMALISATION = True\n",
    "USE_UPSAMPLE = True # otherwise use transpose\n",
    "\n",
    "metrics = [\n",
    "    metr.dice_coef_labels,\n",
    "    metr.dice_coef_myo,\n",
    "    metr.dice_coef_lv,\n",
    "    metr.dice_coef_rv,\n",
    "]\n",
    "\n",
    "LOSS_FUNCTION = metr.bce_dice_jac_loss\n",
    "\n",
    "Console_and_file_logger(EXPERIMENT, logging.INFO)\n",
    "\n",
    "\n",
    "# Define a config for param injection,\n",
    "# save a serialized version, \n",
    "# make sure all paths exist\n",
    "config = init_config(locals(), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 2D slices from patients with 5 labelled timesteps (193 of 202 patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reports/motion/2D/gcn/only_2d_slices_with_5_timesteps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-10 08:50:08,537 INFO Create DataGenerator\n",
      "2019-10-10 08:50:08,570 INFO Datagenerator created with: \n",
      " shape: [224, 224]\n",
      " batchsize: 2\n",
      " Scaler: MinMax\n",
      " Images: 10764 \n",
      " Augment_grid: False \n",
      " Thread workers: 4\n",
      "2019-10-10 08:50:08,570 INFO No augmentation\n"
     ]
    }
   ],
   "source": [
    "from src.data.generators import MotionDataGenerator\n",
    "# create a list of z slices with t_n and t_n+1 , not possible for the last timestep\n",
    "t_1 = np.concatenate([df[df['t_norm'] == 0]['x_path'].values, df[df['t_norm'] == 1]['x_path'].values, df[df['t_norm'] == 2]['x_path'].values, df[df['t_norm'] == 3]['x_path'].values])\n",
    "t_2 = np.concatenate([df[df['t_norm'] == 1]['x_path'].values, df[df['t_norm'] == 2]['x_path'].values, df[df['t_norm'] == 3]['x_path'].values, df[df['t_norm'] == 4]['x_path'].values])\n",
    "batch_generator = MotionDataGenerator(t_1, t_2, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8fbd1e3f45149b7b6da6ae7693a9912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2691, description='batch', max=5382), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select batch generator output\n",
    "x = ''\n",
    "y = ''\n",
    "@interact\n",
    "def select_batch(batch = (0,len(batch_generator), 1)):\n",
    "    global x, y\n",
    "    input_ , output_ = batch_generator.__getitem__(batch)\n",
    "    x = input_[0]\n",
    "    y = output_[0]\n",
    "    logging.info(x.shape)\n",
    "    logging.info(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94cc05f1ada4b739f67e1e4814debd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='im', max=1), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def select_image_in_batch(im = (0,x.shape[0]- 1, 1)):\n",
    "    \n",
    "    # define a different logging level to make the generator steps visible\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    show_2D_or_3D(x[im])\n",
    "    plt.show()\n",
    "    show_2D_or_3D(y[im])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('src/models/ext/neuron')\n",
    "sys.path.append('src/models/ext/pynd-lib')\n",
    "sys.path.append('src/models/ext/pytools-lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.src.networks import cvpr2018_net\n",
    "from keras.losses import mean_squared_error as mse\n",
    "from keras.utils import multi_gpu_model\n",
    "from src.models.src.losses import Grad\n",
    "gpu_ids = config.get('GPU_IDS', '1').split(',')\n",
    "\n",
    "model = cvpr2018_net([224,224], enc_nf=[16,32,32,32], dec_nf=[32,32,32,32,16,3])\n",
    "model = multi_gpu_model(model, gpus=len(gpu_ids), cpu_merge=False) if (len(gpu_ids) > 1) else model\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=['mse', Grad('l2').loss],\n",
    "                         loss_weights=[1.0, 0.01]) # values used by the CVPR paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 224, 224, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 224, 224, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 224, 224, 1)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 224, 224, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 224, 224, 1)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 [(None, 224, 224, 1) 88641       lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_transformer_1 (Concaten (None, 224, 224, 1)  0           model_2[1][0]                    \n",
      "                                                                 model_2[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flow (Concatenate)              (None, 224, 224, 2)  0           model_2[1][1]                    \n",
      "                                                                 model_2[2][1]                    \n",
      "==================================================================================================\n",
      "Total params: 88,641\n",
      "Trainable params: 88,641\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file=os.path.join(config.get('CONFIG_PATH'),'model.png'), show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-10 08:50:23,952 INFO Fit model, start trainings process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5382/5382 [==============================] - 39s 7ms/step - loss: 0.0019 - spatial_transformer_1_loss: 0.0018 - flow_loss: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-10 08:51:07,550 INFO Saved model to disk: models/motion/2D/gcn/2019-10-10_08_50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: loss improved from inf to 0.00188, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 2/100\n",
      "5382/5382 [==============================] - 36s 7ms/step - loss: 0.0015 - spatial_transformer_1_loss: 0.0013 - flow_loss: 0.0169\n",
      "\n",
      "Epoch 00002: loss improved from 0.00188 to 0.00151, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 3/100\n",
      "5382/5382 [==============================] - 36s 7ms/step - loss: 0.0014 - spatial_transformer_1_loss: 0.0013 - flow_loss: 0.0183\n",
      "\n",
      "Epoch 00003: loss improved from 0.00151 to 0.00144, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 4/100\n",
      "5382/5382 [==============================] - 36s 7ms/step - loss: 0.0014 - spatial_transformer_1_loss: 0.0012 - flow_loss: 0.0190\n",
      "\n",
      "Epoch 00004: loss improved from 0.00144 to 0.00140, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 5/100\n",
      "5382/5382 [==============================] - 37s 7ms/step - loss: 0.0014 - spatial_transformer_1_loss: 0.0012 - flow_loss: 0.0195\n",
      "\n",
      "Epoch 00005: loss improved from 0.00140 to 0.00138, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 6/100\n",
      "5382/5382 [==============================] - 37s 7ms/step - loss: 0.0014 - spatial_transformer_1_loss: 0.0012 - flow_loss: 0.0197\n",
      "\n",
      "Epoch 00006: loss improved from 0.00138 to 0.00136, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 7/100\n",
      "5382/5382 [==============================] - 37s 7ms/step - loss: 0.0013 - spatial_transformer_1_loss: 0.0011 - flow_loss: 0.0199\n",
      "\n",
      "Epoch 00007: loss improved from 0.00136 to 0.00135, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 8/100\n",
      "5382/5382 [==============================] - 36s 7ms/step - loss: 0.0013 - spatial_transformer_1_loss: 0.0011 - flow_loss: 0.0201\n",
      "\n",
      "Epoch 00008: loss improved from 0.00135 to 0.00134, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 9/100\n",
      "5382/5382 [==============================] - 36s 7ms/step - loss: 0.0013 - spatial_transformer_1_loss: 0.0011 - flow_loss: 0.0202\n",
      "\n",
      "Epoch 00009: loss improved from 0.00134 to 0.00133, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 10/100\n",
      "5382/5382 [==============================] - 36s 7ms/step - loss: 0.0013 - spatial_transformer_1_loss: 0.0011 - flow_loss: 0.0202\n",
      "\n",
      "Epoch 00010: loss improved from 0.00133 to 0.00129, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 11/100\n",
      "5382/5382 [==============================] - 37s 7ms/step - loss: 0.0013 - spatial_transformer_1_loss: 0.0011 - flow_loss: 0.0203\n",
      "\n",
      "Epoch 00011: loss improved from 0.00129 to 0.00128, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 12/100\n",
      "5382/5382 [==============================] - 37s 7ms/step - loss: 0.0013 - spatial_transformer_1_loss: 0.0011 - flow_loss: 0.0203\n",
      "\n",
      "Epoch 00012: loss improved from 0.00128 to 0.00128, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 13/100\n",
      "5382/5382 [==============================] - 37s 7ms/step - loss: 0.0013 - spatial_transformer_1_loss: 0.0011 - flow_loss: 0.0204\n",
      "\n",
      "Epoch 00013: loss improved from 0.00128 to 0.00127, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 14/100\n",
      "5382/5382 [==============================] - 36s 7ms/step - loss: 0.0013 - spatial_transformer_1_loss: 0.0011 - flow_loss: 0.0204\n",
      "\n",
      "Epoch 00014: loss improved from 0.00127 to 0.00127, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 15/100\n",
      "5382/5382 [==============================] - 37s 7ms/step - loss: 0.0013 - spatial_transformer_1_loss: 0.0011 - flow_loss: 0.0204\n",
      "\n",
      "Epoch 00015: loss improved from 0.00127 to 0.00127, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 16/100\n",
      "5382/5382 [==============================] - 36s 7ms/step - loss: 0.0012 - spatial_transformer_1_loss: 0.0010 - flow_loss: 0.0204\n",
      "\n",
      "Epoch 00016: loss improved from 0.00127 to 0.00125, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 17/100\n",
      "5382/5382 [==============================] - 37s 7ms/step - loss: 0.0012 - spatial_transformer_1_loss: 0.0010 - flow_loss: 0.0204\n",
      "\n",
      "Epoch 00017: loss improved from 0.00125 to 0.00124, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 18/100\n",
      "5382/5382 [==============================] - 38s 7ms/step - loss: 0.0012 - spatial_transformer_1_loss: 0.0010 - flow_loss: 0.0204\n",
      "\n",
      "Epoch 00018: loss improved from 0.00124 to 0.00124, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 19/100\n",
      "5382/5382 [==============================] - 38s 7ms/step - loss: 0.0012 - spatial_transformer_1_loss: 0.0010 - flow_loss: 0.0205\n",
      "\n",
      "Epoch 00019: loss improved from 0.00124 to 0.00124, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 20/100\n",
      "5382/5382 [==============================] - 38s 7ms/step - loss: 0.0012 - spatial_transformer_1_loss: 0.0010 - flow_loss: 0.0205\n",
      "\n",
      "Epoch 00020: loss improved from 0.00124 to 0.00124, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 21/100\n",
      "5382/5382 [==============================] - 37s 7ms/step - loss: 0.0012 - spatial_transformer_1_loss: 0.0010 - flow_loss: 0.0205\n",
      "\n",
      "Epoch 00021: loss improved from 0.00124 to 0.00123, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 22/100\n",
      "5382/5382 [==============================] - 37s 7ms/step - loss: 0.0012 - spatial_transformer_1_loss: 0.0010 - flow_loss: 0.0205\n",
      "\n",
      "Epoch 00022: loss improved from 0.00123 to 0.00123, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 23/100\n",
      "5382/5382 [==============================] - 37s 7ms/step - loss: 0.0012 - spatial_transformer_1_loss: 0.0010 - flow_loss: 0.0205\n",
      "\n",
      "Epoch 00023: loss improved from 0.00123 to 0.00123, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 24/100\n",
      "5382/5382 [==============================] - 38s 7ms/step - loss: 0.0012 - spatial_transformer_1_loss: 0.0010 - flow_loss: 0.0205\n",
      "\n",
      "Epoch 00024: loss improved from 0.00123 to 0.00122, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 25/100\n",
      "5382/5382 [==============================] - 38s 7ms/step - loss: 0.0012 - spatial_transformer_1_loss: 0.0010 - flow_loss: 0.0205\n",
      "\n",
      "Epoch 00025: loss improved from 0.00122 to 0.00122, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 26/100\n",
      "5382/5382 [==============================] - 38s 7ms/step - loss: 0.0012 - spatial_transformer_1_loss: 0.0010 - flow_loss: 0.0205\n",
      "\n",
      "Epoch 00026: loss improved from 0.00122 to 0.00122, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 27/100\n",
      "5382/5382 [==============================] - 38s 7ms/step - loss: 0.0012 - spatial_transformer_1_loss: 0.0010 - flow_loss: 0.0205\n",
      "\n",
      "Epoch 00027: loss improved from 0.00122 to 0.00122, saving model to models/motion/2D/gcn/2019-10-10_08_50/checkpoint.h5\n",
      "Epoch 28/100\n",
      " 502/5382 [=>............................] - ETA: 35s - loss: 0.0012 - spatial_transformer_1_loss: 0.0010 - flow_loss: 0.0208"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ee17bb7faca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#use_multiprocessing=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initial_epoch = 0\n",
    "# training\n",
    "\n",
    "# start a new main process for this training to free gpu memory afterwards\n",
    "logging.info('Fit model, start trainings process')\n",
    "# fit model with trainingsgenerator\n",
    "results = model.fit_generator(\n",
    "    generator=batch_generator,\n",
    "    epochs=100,\n",
    "    callbacks = get_callbacks(config),\n",
    "    steps_per_epoch = len(batch_generator),\n",
    "    initial_epoch=initial_epoch,\n",
    "    max_queue_size=30,\n",
    "    workers=8,\n",
    "    #use_multiprocessing=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-10 11:13:43,982 INFO Create DataGenerator\n",
      "2019-10-10 11:13:44,014 INFO Datagenerator created with: \n",
      " shape: [224, 224]\n",
      " batchsize: 64\n",
      " Scaler: MinMax\n",
      " Images: 10764 \n",
      " Augment_grid: False \n",
      " Thread workers: 4\n",
      "2019-10-10 11:13:44,014 INFO No augmentation\n"
     ]
    }
   ],
   "source": [
    "# use the batch generator for training\n",
    "test_config = config.copy()\n",
    "test_config['SHUFFLE'] = False\n",
    "test_config['BATCHSIZE'] = 64\n",
    "test_config['AUGMENT_GRID'] = False\n",
    "test_generator = MotionDataGenerator(t_1, t_2, test_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54cb0fd18e74725912d8cfca242e093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=84, description='batch', max=168), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select batch generator output\n",
    "x = ''\n",
    "y = ''\n",
    "input_ = ''\n",
    "@interact\n",
    "def select_batch(batch = (0,len(test_generator), 1)):\n",
    "    global x, y, input_\n",
    "    input_ , output_ = test_generator.__getitem__(batch)\n",
    "    x = input_[0]\n",
    "    y = output_[0]\n",
    "    logging.info(x.shape)\n",
    "    logging.info(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(input_)\n",
    "\n",
    "warped, flowfield = pred\n",
    "warped.shape\n",
    "flowfield.shape\n",
    "flowfield[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 224, 224, 2)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>fold</th>\n",
       "      <th>x_path</th>\n",
       "      <th>y_path</th>\n",
       "      <th>modality</th>\n",
       "      <th>patient</th>\n",
       "      <th>t</th>\n",
       "      <th>z</th>\n",
       "      <th>t_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240</td>\n",
       "      <td>43789</td>\n",
       "      <td>0</td>\n",
       "      <td>data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...</td>\n",
       "      <td>data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...</td>\n",
       "      <td>train</td>\n",
       "      <td>0003-04NEJQUZ-2007-03-13</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>241</td>\n",
       "      <td>43790</td>\n",
       "      <td>0</td>\n",
       "      <td>data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...</td>\n",
       "      <td>data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...</td>\n",
       "      <td>train</td>\n",
       "      <td>0003-04NEJQUZ-2007-03-13</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>242</td>\n",
       "      <td>43791</td>\n",
       "      <td>0</td>\n",
       "      <td>data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...</td>\n",
       "      <td>data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...</td>\n",
       "      <td>train</td>\n",
       "      <td>0003-04NEJQUZ-2007-03-13</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>43792</td>\n",
       "      <td>0</td>\n",
       "      <td>data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...</td>\n",
       "      <td>data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...</td>\n",
       "      <td>train</td>\n",
       "      <td>0003-04NEJQUZ-2007-03-13</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>244</td>\n",
       "      <td>43793</td>\n",
       "      <td>0</td>\n",
       "      <td>data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...</td>\n",
       "      <td>data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...</td>\n",
       "      <td>train</td>\n",
       "      <td>0003-04NEJQUZ-2007-03-13</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  fold  \\\n",
       "0         240         43789     0   \n",
       "1         241         43790     0   \n",
       "2         242         43791     0   \n",
       "3         243         43792     0   \n",
       "4         244         43793     0   \n",
       "\n",
       "                                              x_path  \\\n",
       "0  data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...   \n",
       "1  data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...   \n",
       "2  data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...   \n",
       "3  data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...   \n",
       "4  data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...   \n",
       "\n",
       "                                              y_path modality  \\\n",
       "0  data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...    train   \n",
       "1  data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...    train   \n",
       "2  data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...    train   \n",
       "3  data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...    train   \n",
       "4  data/raw/tetra/2D/train/0003-04NEJQUZ-2007-03-...    train   \n",
       "\n",
       "                    patient   t   z  t_norm  \n",
       "0  0003-04NEJQUZ-2007-03-13  12   0       1  \n",
       "1  0003-04NEJQUZ-2007-03-13  12  10       1  \n",
       "2  0003-04NEJQUZ-2007-03-13  12  11       1  \n",
       "3  0003-04NEJQUZ-2007-03-13  12  12       1  \n",
       "4  0003-04NEJQUZ-2007-03-13  12  13       1  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flowfield.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('reports/numpy_files/input64.npy', input_)\n",
    "np.save('reports/numpy_files/warped64.npy', warped)\n",
    "np.save('reports/numpy_files/flowfield64.npy', flowfield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped = np.load('reports/numpy_files/warped.npy')\n",
    "flowfield = np.load('reports/numpy_files/flowfield.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='img', max=63), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def show_flowfield(img = (0,x.shape[0]- 1)):\n",
    "    fig, (ax1, ax2, ax3, ax4, ax5, ax6, ax7) = plt.subplots(1,7, figsize=(30,4))\n",
    "\n",
    "    \n",
    "    ax1.set_title('X-flow')\n",
    "    ax1.imshow(flowfield[img,:,:,0]);\n",
    "    ax2.set_title('Y-flow')\n",
    "    ax2.imshow(flowfield[img,:,:,1]);\n",
    "    ax3.set_title('image_t0')\n",
    "    ax3.imshow(x[img,:,:,0])\n",
    "    ax4.set_title('image_warped')\n",
    "    ax4.imshow(warped[img,:,:,0]) # x warped, should bee similar to y\n",
    "    ax5.set_title('image_tn')\n",
    "    ax5.imshow(y[img,:,:,0]) # target\n",
    "    diff_ = y[img,:,:,0]- warped[img,:,:,0]\n",
    "    ax6.set_title('gt - image warped \\ndiff: {:4f} '.format(abs(diff_.sum())))\n",
    "    ax6.imshow(diff_) # difference\n",
    "    ax7.set_title('quiver flowfield')\n",
    "    \n",
    "    flow_X = flowfield[img,:,:,0]\n",
    "    flow_Y = flowfield[img,:,:,1]\n",
    "\n",
    "    N = 5\n",
    "    Fx = flow_X[::N, ::N]\n",
    "    Fy = flow_Y[::N, ::N]\n",
    "\n",
    "    nrows, ncols = Fx.shape\n",
    "    nx = 2\n",
    "    ny = 2\n",
    "    x_ = np.linspace(-nx, nx, ncols)\n",
    "    y_ = np.linspace(-ny, ny, nrows)\n",
    "    xi, yi = np.meshgrid(x_, y_, indexing='ij')\n",
    "\n",
    "    #plt.axes([0.065, 0.065, 0.9, 0.9])#\n",
    "    ax7.quiver(yi, -xi , Fx, Fy, alpha=.5)\n",
    "    ax7.quiver(yi, -xi, Fx, Fy, edgecolor='k', facecolor='none', linewidth=.5)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='img', max=63), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_quiver_from_motion(img=(0,flowfield.shape[0]-1)):\n",
    "    \n",
    "    fix, ax = plt.subplots(figsize=(12,12))\n",
    "    \n",
    "    Y = flowfield[img,:,:,0]\n",
    "    X = flowfield[img,:,:,1]\n",
    "\n",
    "    N = 4\n",
    "    Fx = X[::N, ::N]\n",
    "    Fy = Y[::N, ::N]\n",
    "\n",
    "    nrows, ncols = Fx.shape\n",
    "    nx = 2\n",
    "    ny = 2\n",
    "    x = np.linspace(-nx, nx, ncols)\n",
    "    print(Fx.shape)\n",
    "    print(Fy.shape)\n",
    "    y = np.linspace(-ny, ny, nrows)\n",
    "    xi, yi = np.meshgrid(x, y, indexing='ij')\n",
    "\n",
    "    #plt.axes([0.065, 0.065, 0.9, 0.9])#\n",
    "    plt.quiver(yi, -xi , Fx, Fy, alpha=.5)\n",
    "    plt.quiver(yi, -xi, Fx, Fy, edgecolor='k', facecolor='none', linewidth=.5)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-5, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'How to plot a vector in matplotlib ?')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X = np.array((0))\n",
    "Y= np.array((0))\n",
    "U = np.array((2))\n",
    "V = np.array((-2))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "q = ax.quiver(X, Y, U, V,units='xy' ,scale=1)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.xlim(-5,5)\n",
    "plt.ylim(-5,5)\n",
    "\n",
    "plt.title('How to plot a vector in matplotlib ?',fontsize=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 50)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'How to plot a vector field using matplotlib ?')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X, Y = np.meshgrid(X[np.newaxis], Y[np.newaxis])\n",
    "\n",
    "x_shape = X.shape\n",
    "\n",
    "U = np.zeros(x_shape)\n",
    "V = np.zeros(x_shape)\n",
    "\n",
    "for i in range(x_shape[0]):\n",
    "    for j in range(x_shape[1]):\n",
    "        U[i,j] = 1.0\n",
    "        V[i,j] = 1.0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "q = ax.quiver(X, Y, U, V, units='xy' ,scale=2, color='red')\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.xlim(0,50)\n",
    "plt.ylim(0,100)\n",
    "\n",
    "plt.title('How to plot a vector field using matplotlib ?',fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
